{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1368,
      "metadata": {
        "id": "ZCUWTBppfCwY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "y6OQowK3fTjV"
      },
      "execution_count": 1369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding,Bidirectional\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "o6eOt-BLfXBk"
      },
      "execution_count": 1370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
        "Hey there! I was just thinking about you the other day. How have you been doing?\n",
        "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
        "I'm so glad we finally have some time to catch up. What's new in your life?\n",
        "Could you believe how crowded the supermarket was this morning? It was insane!\n",
        "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
        "How was your weekend? Did you end up going to that concert you mentioned?\n",
        "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
        "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
        "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
        "I can't believe how fast this week has gone by. Is it Friday already?\n",
        "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
        "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
        "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
        "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
        "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
        "I love your outfit today! That color really brings out your eyes beautifully.\n",
        "Could you help me with this computer problem? I'm completely stuck right now.\n",
        "How's work been treating you lately? You seem really busy these past few weeks.\n",
        "I'm thinking about redecorating my living room. What do you think would look nice?\n",
        "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
        "I just finished reading the most amazing book. You should definitely check it out.\n",
        "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
        "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
        "How are you feeling today? You look much better than the last time I saw you.\n",
        "I wanted to apologize for missing your birthday party. Something came up at work.\n",
        "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
        "Could you recommend a good mechanic? My car has been making strange noises.\n",
        "I'm really looking forward to the weekend. This work week has been exhausting!\"\"\""
      ],
      "metadata": {
        "id": "_ESQyhj_fdQ1"
      },
      "execution_count": 1371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvVG5nKf1RO",
        "outputId": "b306a968-ce59-40c1-e950-de6dc2da639a"
      },
      "execution_count": 1372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
            "Hey there! I was just thinking about you the other day. How have you been doing?\n",
            "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
            "I'm so glad we finally have some time to catch up. What's new in your life?\n",
            "Could you believe how crowded the supermarket was this morning? It was insane!\n",
            "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
            "How was your weekend? Did you end up going to that concert you mentioned?\n",
            "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
            "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
            "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
            "I can't believe how fast this week has gone by. Is it Friday already?\n",
            "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
            "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
            "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
            "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
            "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
            "I love your outfit today! That color really brings out your eyes beautifully.\n",
            "Could you help me with this computer problem? I'm completely stuck right now.\n",
            "How's work been treating you lately? You seem really busy these past few weeks.\n",
            "I'm thinking about redecorating my living room. What do you think would look nice?\n",
            "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
            "I just finished reading the most amazing book. You should definitely check it out.\n",
            "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
            "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
            "How are you feeling today? You look much better than the last time I saw you.\n",
            "I wanted to apologize for missing your birthday party. Something came up at work.\n",
            "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
            "Could you recommend a good mechanic? My car has been making strange noises.\n",
            "I'm really looking forward to the weekend. This work week has been exhausting!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an object of tokenizer class\n",
        "tokenizer = Tokenizer(oov_token='<NOTHING>') # if any word came out side the train data it will simple print nothing"
      ],
      "metadata": {
        "id": "7qvmCUaQf2FW"
      },
      "execution_count": 1373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "qyeooTX6f6sG"
      },
      "execution_count": 1374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the word indes\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TcQK_aBf_z-",
        "outputId": "b3b53358-45f8-4a6c-feaf-05a2cca0443f"
      },
      "execution_count": 1375,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<NOTHING>': 1,\n",
              " 'you': 2,\n",
              " 'the': 3,\n",
              " 'i': 4,\n",
              " 'your': 5,\n",
              " 'to': 6,\n",
              " \"i'm\": 7,\n",
              " 'this': 8,\n",
              " 'how': 9,\n",
              " 'have': 10,\n",
              " 'a': 11,\n",
              " 'new': 12,\n",
              " 'it': 13,\n",
              " 'for': 14,\n",
              " 'that': 15,\n",
              " 'really': 16,\n",
              " 'did': 17,\n",
              " 'was': 18,\n",
              " 'just': 19,\n",
              " 'been': 20,\n",
              " 'up': 21,\n",
              " 'weekend': 22,\n",
              " 'today': 23,\n",
              " 'morning': 24,\n",
              " 'last': 25,\n",
              " 'about': 26,\n",
              " 'what': 27,\n",
              " 'so': 28,\n",
              " \"what's\": 29,\n",
              " 'could': 30,\n",
              " 'is': 31,\n",
              " 'do': 32,\n",
              " 'week': 33,\n",
              " 'has': 34,\n",
              " 'on': 35,\n",
              " 'work': 36,\n",
              " 'good': 37,\n",
              " 'thinking': 38,\n",
              " 'day': 39,\n",
              " 'doing': 40,\n",
              " 'had': 41,\n",
              " 'weather': 42,\n",
              " 'we': 43,\n",
              " 'time': 44,\n",
              " 'believe': 45,\n",
              " 'wanted': 46,\n",
              " 'me': 47,\n",
              " 'amazing': 48,\n",
              " 'late': 49,\n",
              " 'like': 50,\n",
              " 'something': 51,\n",
              " 'street': 52,\n",
              " 'nice': 53,\n",
              " 'would': 54,\n",
              " 'restaurant': 55,\n",
              " \"how's\": 56,\n",
              " 'at': 57,\n",
              " 'should': 58,\n",
              " 'are': 59,\n",
              " 'year': 60,\n",
              " 'love': 61,\n",
              " 'out': 62,\n",
              " 'my': 63,\n",
              " 'look': 64,\n",
              " 'reading': 65,\n",
              " 'sleep': 66,\n",
              " 'night': 67,\n",
              " 'any': 68,\n",
              " 'interesting': 69,\n",
              " 'dreams': 70,\n",
              " 'hey': 71,\n",
              " 'there': 72,\n",
              " 'other': 73,\n",
              " 'beautiful': 74,\n",
              " 'outside': 75,\n",
              " 'chance': 76,\n",
              " 'enjoy': 77,\n",
              " 'yet': 78,\n",
              " 'glad': 79,\n",
              " 'finally': 80,\n",
              " 'some': 81,\n",
              " 'catch': 82,\n",
              " 'in': 83,\n",
              " 'life': 84,\n",
              " 'crowded': 85,\n",
              " 'supermarket': 86,\n",
              " 'insane': 87,\n",
              " 'say': 88,\n",
              " 'thank': 89,\n",
              " 'again': 90,\n",
              " 'helping': 91,\n",
              " 'move': 92,\n",
              " \"you're\": 93,\n",
              " 'end': 94,\n",
              " 'going': 95,\n",
              " 'concert': 96,\n",
              " 'mentioned': 97,\n",
              " 'sorry': 98,\n",
              " 'running': 99,\n",
              " 'traffic': 100,\n",
              " 'absolutely': 101,\n",
              " 'terrible': 102,\n",
              " 'feel': 103,\n",
              " 'having': 104,\n",
              " 'lunch': 105,\n",
              " 'craving': 106,\n",
              " 'spicy': 107,\n",
              " 'myself': 108,\n",
              " 'seen': 109,\n",
              " 'coffee': 110,\n",
              " 'shop': 111,\n",
              " 'opened': 112,\n",
              " 'down': 113,\n",
              " 'looks': 114,\n",
              " \"can't\": 115,\n",
              " 'fast': 116,\n",
              " 'gone': 117,\n",
              " 'by': 118,\n",
              " 'friday': 119,\n",
              " 'already': 120,\n",
              " 'grab': 121,\n",
              " 'dinner': 122,\n",
              " 'sometime': 123,\n",
              " 'know': 124,\n",
              " 'great': 125,\n",
              " 'family': 126,\n",
              " 'heard': 127,\n",
              " 'sister': 128,\n",
              " 'baby': 129,\n",
              " 'congratulations': 130,\n",
              " 'tired': 131,\n",
              " 'stayed': 132,\n",
              " 'way': 133,\n",
              " 'too': 134,\n",
              " 'watching': 135,\n",
              " 'show': 136,\n",
              " 'netflix': 137,\n",
              " 'hear': 138,\n",
              " 'big': 139,\n",
              " 'sale': 140,\n",
              " 'happening': 141,\n",
              " 'mall': 142,\n",
              " 'go': 143,\n",
              " 'plan': 144,\n",
              " 'holidays': 145,\n",
              " 'traveling': 146,\n",
              " 'anywhere': 147,\n",
              " 'exciting': 148,\n",
              " 'outfit': 149,\n",
              " 'color': 150,\n",
              " 'brings': 151,\n",
              " 'eyes': 152,\n",
              " 'beautifully': 153,\n",
              " 'help': 154,\n",
              " 'with': 155,\n",
              " 'computer': 156,\n",
              " 'problem': 157,\n",
              " 'completely': 158,\n",
              " 'stuck': 159,\n",
              " 'right': 160,\n",
              " 'now': 161,\n",
              " 'treating': 162,\n",
              " 'lately': 163,\n",
              " 'seem': 164,\n",
              " 'busy': 165,\n",
              " 'these': 166,\n",
              " 'past': 167,\n",
              " 'few': 168,\n",
              " 'weeks': 169,\n",
              " 'redecorating': 170,\n",
              " 'living': 171,\n",
              " 'room': 172,\n",
              " 'think': 173,\n",
              " 'forecast': 174,\n",
              " 'says': 175,\n",
              " 'might': 176,\n",
              " 'rain': 177,\n",
              " 'tomorrow': 178,\n",
              " \"don't\": 179,\n",
              " 'forget': 180,\n",
              " 'umbrella': 181,\n",
              " 'finished': 182,\n",
              " 'most': 183,\n",
              " 'book': 184,\n",
              " 'definitely': 185,\n",
              " 'check': 186,\n",
              " 'tried': 187,\n",
              " 'italian': 188,\n",
              " 'main': 189,\n",
              " 'pasta': 190,\n",
              " 'incredible': 191,\n",
              " 'excited': 192,\n",
              " 'summer': 193,\n",
              " 'vacation': 194,\n",
              " \"we're\": 195,\n",
              " 'planning': 196,\n",
              " 'visit': 197,\n",
              " 'europe': 198,\n",
              " 'feeling': 199,\n",
              " 'much': 200,\n",
              " 'better': 201,\n",
              " 'than': 202,\n",
              " 'saw': 203,\n",
              " 'apologize': 204,\n",
              " 'missing': 205,\n",
              " 'birthday': 206,\n",
              " 'party': 207,\n",
              " 'came': 208,\n",
              " 'favorite': 209,\n",
              " 'thing': 210,\n",
              " 'lazy': 211,\n",
              " 'sunday': 212,\n",
              " 'afternoon': 213,\n",
              " 'recommend': 214,\n",
              " 'mechanic': 215,\n",
              " 'car': 216,\n",
              " 'making': 217,\n",
              " 'strange': 218,\n",
              " 'noises': 219,\n",
              " 'looking': 220,\n",
              " 'forward': 221,\n",
              " 'exhausting': 222}"
            ]
          },
          "metadata": {},
          "execution_count": 1375
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the words\n",
        "tokenizer.word_index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfLz4PogCOO",
        "outputId": "6ccd6767-a490-42ff-a0f7-3056bb3f69af"
      },
      "execution_count": 1376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<NOTHING>', 'you', 'the', 'i', 'your', 'to', \"i'm\", 'this', 'how', 'have', 'a', 'new', 'it', 'for', 'that', 'really', 'did', 'was', 'just', 'been', 'up', 'weekend', 'today', 'morning', 'last', 'about', 'what', 'so', \"what's\", 'could', 'is', 'do', 'week', 'has', 'on', 'work', 'good', 'thinking', 'day', 'doing', 'had', 'weather', 'we', 'time', 'believe', 'wanted', 'me', 'amazing', 'late', 'like', 'something', 'street', 'nice', 'would', 'restaurant', \"how's\", 'at', 'should', 'are', 'year', 'love', 'out', 'my', 'look', 'reading', 'sleep', 'night', 'any', 'interesting', 'dreams', 'hey', 'there', 'other', 'beautiful', 'outside', 'chance', 'enjoy', 'yet', 'glad', 'finally', 'some', 'catch', 'in', 'life', 'crowded', 'supermarket', 'insane', 'say', 'thank', 'again', 'helping', 'move', \"you're\", 'end', 'going', 'concert', 'mentioned', 'sorry', 'running', 'traffic', 'absolutely', 'terrible', 'feel', 'having', 'lunch', 'craving', 'spicy', 'myself', 'seen', 'coffee', 'shop', 'opened', 'down', 'looks', \"can't\", 'fast', 'gone', 'by', 'friday', 'already', 'grab', 'dinner', 'sometime', 'know', 'great', 'family', 'heard', 'sister', 'baby', 'congratulations', 'tired', 'stayed', 'way', 'too', 'watching', 'show', 'netflix', 'hear', 'big', 'sale', 'happening', 'mall', 'go', 'plan', 'holidays', 'traveling', 'anywhere', 'exciting', 'outfit', 'color', 'brings', 'eyes', 'beautifully', 'help', 'with', 'computer', 'problem', 'completely', 'stuck', 'right', 'now', 'treating', 'lately', 'seem', 'busy', 'these', 'past', 'few', 'weeks', 'redecorating', 'living', 'room', 'think', 'forecast', 'says', 'might', 'rain', 'tomorrow', \"don't\", 'forget', 'umbrella', 'finished', 'most', 'book', 'definitely', 'check', 'tried', 'italian', 'main', 'pasta', 'incredible', 'excited', 'summer', 'vacation', \"we're\", 'planning', 'visit', 'europe', 'feeling', 'much', 'better', 'than', 'saw', 'apologize', 'missing', 'birthday', 'party', 'came', 'favorite', 'thing', 'lazy', 'sunday', 'afternoon', 'recommend', 'mechanic', 'car', 'making', 'strange', 'noises', 'looking', 'forward', 'exhausting'])"
            ]
          },
          "metadata": {},
          "execution_count": 1376
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the values\n",
        "tokenizer.word_index.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amN1KgkvggiH",
        "outputId": "e52e9eff-f710-4e08-f894-d91c5a6d23cd"
      },
      "execution_count": 1377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222])"
            ]
          },
          "metadata": {},
          "execution_count": 1377
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg3qV7JlkKPH",
        "outputId": "eaf14c65-f9c9-4fb5-e11d-d6be59659bbf"
      },
      "execution_count": 1378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "metadata": {},
          "execution_count": 1378
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the sentences based on the text sequence\n",
        "for sentence in data.split(\"\\n\"):\n",
        "  if sentence.strip():\n",
        "    print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svfldnylgi1O",
        "outputId": "4175440a-f919-4a1c-a9a0-e4ab5bbb3490"
      },
      "execution_count": 1379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70]\n",
            "[71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40]\n",
            "[27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78]\n",
            "[7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84]\n",
            "[30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87]\n",
            "[4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48]\n",
            "[9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97]\n",
            "[7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24]\n",
            "[27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108]\n",
            "[10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53]\n",
            "[4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120]\n",
            "[54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55]\n",
            "[56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130]\n",
            "[7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137]\n",
            "[17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143]\n",
            "[29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60]\n",
            "[4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153]\n",
            "[30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161]\n",
            "[56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169]\n",
            "[7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53]\n",
            "[3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181]\n",
            "[4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62]\n",
            "[10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191]\n",
            "[7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60]\n",
            "[9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2]\n",
            "[4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36]\n",
            "[29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65]\n",
            "[30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219]\n",
            "[7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the input and the output sequence\n",
        "input_sequences = []\n",
        "for sentence in data.split('\\n'):\n",
        "  if sentence.strip():\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] # convert the sentences based on the text sequence\n",
        "\n",
        "    for i in range(1,len(tokenized_sentence)):\n",
        "      input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "GvTkEIJWhFbf"
      },
      "execution_count": 1380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for 36 the next word will be 23\n",
        "# for 23 and 36 the next word will be 8\n",
        "\n",
        "\"\"\"\n",
        "so if X = 36 then y = 23\n",
        "if X = 36,23 then y = 8\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4B1mrA_-iU7I",
        "outputId": "1088d66c-f218-4df8-be3e-24a9a0064856"
      },
      "execution_count": 1381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nso if X = 36 then y = 23\\nif X = 36,23 then y = 8\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1381
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOi9rLLSiR4X",
        "outputId": "fb94e526-14ca-4d40-93ed-c57d873eaac5"
      },
      "execution_count": 1382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[37, 24],\n",
              " [37, 24, 9],\n",
              " [37, 24, 9, 17],\n",
              " [37, 24, 9, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66],\n",
              " [37, 24, 9, 17, 2, 66, 25],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70],\n",
              " [71, 72],\n",
              " [71, 72, 4],\n",
              " [71, 72, 4, 18],\n",
              " [71, 72, 4, 18, 19],\n",
              " [71, 72, 4, 18, 19, 38],\n",
              " [71, 72, 4, 18, 19, 38, 26],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40],\n",
              " [27, 11],\n",
              " [27, 11, 74],\n",
              " [27, 11, 74, 39],\n",
              " [27, 11, 74, 39, 75],\n",
              " [27, 11, 74, 39, 75, 10],\n",
              " [27, 11, 74, 39, 75, 10, 2],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78],\n",
              " [7, 28],\n",
              " [7, 28, 79],\n",
              " [7, 28, 79, 43],\n",
              " [7, 28, 79, 43, 80],\n",
              " [7, 28, 79, 43, 80, 10],\n",
              " [7, 28, 79, 43, 80, 10, 81],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84],\n",
              " [30, 2],\n",
              " [30, 2, 45],\n",
              " [30, 2, 45, 9],\n",
              " [30, 2, 45, 9, 85],\n",
              " [30, 2, 45, 9, 85, 3],\n",
              " [30, 2, 45, 9, 85, 3, 86],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87],\n",
              " [4, 19],\n",
              " [4, 19, 46],\n",
              " [4, 19, 46, 6],\n",
              " [4, 19, 46, 6, 88],\n",
              " [4, 19, 46, 6, 88, 89],\n",
              " [4, 19, 46, 6, 88, 89, 2],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48],\n",
              " [9, 18],\n",
              " [9, 18, 5],\n",
              " [9, 18, 5, 22],\n",
              " [9, 18, 5, 22, 17],\n",
              " [9, 18, 5, 22, 17, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97],\n",
              " [7, 16],\n",
              " [7, 16, 98],\n",
              " [7, 16, 98, 7],\n",
              " [7, 16, 98, 7, 99],\n",
              " [7, 16, 98, 7, 99, 49],\n",
              " [7, 16, 98, 7, 99, 49, 100],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24],\n",
              " [27, 32],\n",
              " [27, 32, 2],\n",
              " [27, 32, 2, 103],\n",
              " [27, 32, 2, 103, 50],\n",
              " [27, 32, 2, 103, 50, 104],\n",
              " [27, 32, 2, 103, 50, 104, 14],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108],\n",
              " [10, 2],\n",
              " [10, 2, 109],\n",
              " [10, 2, 109, 3],\n",
              " [10, 2, 109, 3, 12],\n",
              " [10, 2, 109, 3, 12, 110],\n",
              " [10, 2, 109, 3, 12, 110, 111],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53],\n",
              " [4, 115],\n",
              " [4, 115, 45],\n",
              " [4, 115, 45, 9],\n",
              " [4, 115, 45, 9, 116],\n",
              " [4, 115, 45, 9, 116, 8],\n",
              " [4, 115, 45, 9, 116, 8, 33],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120],\n",
              " [54, 2],\n",
              " [54, 2, 50],\n",
              " [54, 2, 50, 6],\n",
              " [54, 2, 50, 6, 121],\n",
              " [54, 2, 50, 6, 121, 122],\n",
              " [54, 2, 50, 6, 121, 122, 123],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55],\n",
              " [56, 5],\n",
              " [56, 5, 126],\n",
              " [56, 5, 126, 40],\n",
              " [56, 5, 126, 40, 4],\n",
              " [56, 5, 126, 40, 4, 127],\n",
              " [56, 5, 126, 40, 4, 127, 5],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130],\n",
              " [7, 28],\n",
              " [7, 28, 131],\n",
              " [7, 28, 131, 23],\n",
              " [7, 28, 131, 23, 4],\n",
              " [7, 28, 131, 23, 4, 132],\n",
              " [7, 28, 131, 23, 4, 132, 21],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137],\n",
              " [17, 2],\n",
              " [17, 2, 138],\n",
              " [17, 2, 138, 26],\n",
              " [17, 2, 138, 26, 3],\n",
              " [17, 2, 138, 26, 3, 139],\n",
              " [17, 2, 138, 26, 3, 139, 140],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143],\n",
              " [29, 5],\n",
              " [29, 5, 144],\n",
              " [29, 5, 144, 14],\n",
              " [29, 5, 144, 14, 3],\n",
              " [29, 5, 144, 14, 3, 145],\n",
              " [29, 5, 144, 14, 3, 145, 59],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60],\n",
              " [4, 61],\n",
              " [4, 61, 5],\n",
              " [4, 61, 5, 149],\n",
              " [4, 61, 5, 149, 23],\n",
              " [4, 61, 5, 149, 23, 15],\n",
              " [4, 61, 5, 149, 23, 15, 150],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153],\n",
              " [30, 2],\n",
              " [30, 2, 154],\n",
              " [30, 2, 154, 47],\n",
              " [30, 2, 154, 47, 155],\n",
              " [30, 2, 154, 47, 155, 8],\n",
              " [30, 2, 154, 47, 155, 8, 156],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161],\n",
              " [56, 36],\n",
              " [56, 36, 20],\n",
              " [56, 36, 20, 162],\n",
              " [56, 36, 20, 162, 2],\n",
              " [56, 36, 20, 162, 2, 163],\n",
              " [56, 36, 20, 162, 2, 163, 2],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169],\n",
              " [7, 38],\n",
              " [7, 38, 26],\n",
              " [7, 38, 26, 170],\n",
              " [7, 38, 26, 170, 63],\n",
              " [7, 38, 26, 170, 63, 171],\n",
              " [7, 38, 26, 170, 63, 171, 172],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53],\n",
              " [3, 42],\n",
              " [3, 42, 174],\n",
              " [3, 42, 174, 175],\n",
              " [3, 42, 174, 175, 13],\n",
              " [3, 42, 174, 175, 13, 176],\n",
              " [3, 42, 174, 175, 13, 176, 177],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181],\n",
              " [4, 19],\n",
              " [4, 19, 182],\n",
              " [4, 19, 182, 65],\n",
              " [4, 19, 182, 65, 3],\n",
              " [4, 19, 182, 65, 3, 183],\n",
              " [4, 19, 182, 65, 3, 183, 48],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62],\n",
              " [10, 2],\n",
              " [10, 2, 187],\n",
              " [10, 2, 187, 15],\n",
              " [10, 2, 187, 15, 12],\n",
              " [10, 2, 187, 15, 12, 188],\n",
              " [10, 2, 187, 15, 12, 188, 55],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191],\n",
              " [7, 28],\n",
              " [7, 28, 192],\n",
              " [7, 28, 192, 14],\n",
              " [7, 28, 192, 14, 193],\n",
              " [7, 28, 192, 14, 193, 194],\n",
              " [7, 28, 192, 14, 193, 194, 195],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60],\n",
              " [9, 59],\n",
              " [9, 59, 2],\n",
              " [9, 59, 2, 199],\n",
              " [9, 59, 2, 199, 23],\n",
              " [9, 59, 2, 199, 23, 2],\n",
              " [9, 59, 2, 199, 23, 2, 64],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2],\n",
              " [4, 46],\n",
              " [4, 46, 6],\n",
              " [4, 46, 6, 204],\n",
              " [4, 46, 6, 204, 14],\n",
              " [4, 46, 6, 204, 14, 205],\n",
              " [4, 46, 6, 204, 14, 205, 5],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36],\n",
              " [29, 5],\n",
              " [29, 5, 209],\n",
              " [29, 5, 209, 210],\n",
              " [29, 5, 209, 210, 6],\n",
              " [29, 5, 209, 210, 6, 32],\n",
              " [29, 5, 209, 210, 6, 32, 35],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65],\n",
              " [30, 2],\n",
              " [30, 2, 214],\n",
              " [30, 2, 214, 11],\n",
              " [30, 2, 214, 11, 37],\n",
              " [30, 2, 214, 11, 37, 215],\n",
              " [30, 2, 214, 11, 37, 215, 63],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219],\n",
              " [7, 16],\n",
              " [7, 16, 220],\n",
              " [7, 16, 220, 221],\n",
              " [7, 16, 220, 221, 6],\n",
              " [7, 16, 220, 221, 6, 3],\n",
              " [7, 16, 220, 221, 6, 3, 22],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]]"
            ]
          },
          "metadata": {},
          "execution_count": 1382
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the maximum length\n",
        "maximum_len = max([len(x) for x in input_sequences])\n",
        "maximum_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIjtdOcOiw5f",
        "outputId": "c2abbcb1-9e33-4677-d06c-e43e35904288"
      },
      "execution_count": 1383,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 1383
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding (pre padding)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = maximum_len, padding='pre')"
      ],
      "metadata": {
        "id": "xbAoCv00iw2X"
      },
      "execution_count": 1384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQFbSHEciw0G",
        "outputId": "c23cfdfa-613b-46bd-8f55-87b9ac6f2773"
      },
      "execution_count": 1385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  37,  24],\n",
              "       [  0,   0,   0, ...,  37,  24,   9],\n",
              "       [  0,   0,   0, ...,  24,   9,  17],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  36,  33,  34],\n",
              "       [  0,   0,   0, ...,  33,  34,  20],\n",
              "       [  0,   0,   0, ...,  34,  20, 222]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 1385
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2CWNeoJiwwX",
        "outputId": "35174ebd-8247-4f95-9fd1-7f22fdbcc7a3"
      },
      "execution_count": 1386,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 1386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TtGo25xiwsI",
        "outputId": "ac7a7985-82b3-4ccf-dd86-f3a5f14b2269"
      },
      "execution_count": 1387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0, 37],\n",
              "       [ 0,  0,  0, ...,  0, 37, 24],\n",
              "       [ 0,  0,  0, ..., 37, 24,  9],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  8, 36, 33],\n",
              "       [ 0,  0,  0, ..., 36, 33, 34],\n",
              "       [ 0,  0,  0, ..., 33, 34, 20]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 1387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6DaSq8j0L2",
        "outputId": "878d8d45-18de-40fe-bd2c-fc6956fc1fb0"
      },
      "execution_count": 1388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 1388
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxZQv2UGiwpb",
        "outputId": "70f6a09e-bc46-47a3-bc85-6686b7078cb4"
      },
      "execution_count": 1389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 24,   9,  17,   2,  66,  25,  67,  17,   2,  10,  68,  69,  70,\n",
              "        72,   4,  18,  19,  38,  26,   2,   3,  73,  39,   9,  10,   2,\n",
              "        20,  40,  11,  74,  39,  75,  10,   2,  41,  11,  76,   6,  77,\n",
              "         3,  42,  78,  28,  79,  43,  80,  10,  81,  44,   6,  82,  21,\n",
              "        29,  12,  83,   5,  84,   2,  45,   9,  85,   3,  86,  18,   8,\n",
              "        24,  13,  18,  87,  19,  46,   6,  88,  89,   2,  90,  14,  91,\n",
              "        47,  92,  25,  22,  93,  48,  18,   5,  22,  17,   2,  94,  21,\n",
              "        95,   6,  15,  96,   2,  97,  16,  98,   7,  99,  49, 100,  31,\n",
              "       101, 102,   8,  24,  32,   2, 103,  50, 104,  14, 105,  23,   7,\n",
              "       106,  51, 107, 108,   2, 109,   3,  12, 110, 111,  15, 112, 113,\n",
              "         3,  52,  13, 114,  16,  53, 115,  45,   9, 116,   8,  33,  34,\n",
              "       117, 118,  31,  13, 119, 120,   2,  50,   6, 121, 122, 123,   8,\n",
              "        33,   4, 124,  11, 125,  12,  55,   5, 126,  40,   4, 127,   5,\n",
              "       128,  19,  41,  11, 129, 130,  28, 131,  23,   4, 132,  21, 133,\n",
              "       134,  49, 135,  15,  12, 136,  35, 137,   2, 138,  26,   3, 139,\n",
              "       140, 141,  57,   3, 142,   8,  22,  43,  58, 143,   5, 144,  14,\n",
              "         3, 145,  59,   2, 146, 147, 148,   8,  60,  61,   5, 149,  23,\n",
              "        15, 150,  16, 151,  62,   5, 152, 153,   2, 154,  47, 155,   8,\n",
              "       156, 157,   7, 158, 159, 160, 161,  36,  20, 162,   2, 163,   2,\n",
              "       164,  16, 165, 166, 167, 168, 169,  38,  26, 170,  63, 171, 172,\n",
              "        27,  32,   2, 173,  54,  64,  53,  42, 174, 175,  13, 176, 177,\n",
              "       178, 179, 180,   5, 181,  19, 182,  65,   3, 183,  48, 184,   2,\n",
              "        58, 185, 186,  13,  62,   2, 187,  15,  12, 188,  55,  35, 189,\n",
              "        52,   3, 190,  31, 191,  28, 192,  14, 193, 194, 195, 196,   6,\n",
              "       197, 198,   8,  60,  59,   2, 199,  23,   2,  64, 200, 201, 202,\n",
              "         3,  25,  44,   4, 203,   2,  46,   6, 204,  14, 205,   5, 206,\n",
              "       207,  51, 208,  21,  57,  36,   5, 209, 210,   6,  32,  35,  11,\n",
              "       211, 212, 213,   4,  61,  65,   2, 214,  11,  37, 215,  63, 216,\n",
              "        34,  20, 217, 218, 219,  16, 220, 221,   6,   3,  22,   8,  36,\n",
              "        33,  34,  20, 222], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 1389
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehDrOC6vjyRI",
        "outputId": "9fd62ec3-9cda-48f8-ae69-ffe9b64b0824"
      },
      "execution_count": 1390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381,)"
            ]
          },
          "metadata": {},
          "execution_count": 1390
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) +1 # +1 fo including the zero index\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2jsydhpZzI",
        "outputId": "9651368a-1ae8-484c-f99d-d3e6fd1ad9ff"
      },
      "execution_count": 1391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "metadata": {},
          "execution_count": 1391
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying One-Hot-Encoding on the traget column"
      ],
      "metadata": {
        "id": "rWhaAC4Xj8cw"
      },
      "execution_count": 1392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y,num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "wnbc0HJQiwnG"
      },
      "execution_count": 1393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYe6jmOviwkR",
        "outputId": "2a871861-eea4-472e-bdd8-96b04a402596"
      },
      "execution_count": 1394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 223)"
            ]
          },
          "metadata": {},
          "execution_count": 1394
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmgP50d0muMo",
        "outputId": "47654f73-5970-493f-df68-d6a2cb1a717a"
      },
      "execution_count": 1395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makin the RNN model"
      ],
      "metadata": {
        "id": "3R4qAkAwiwcm"
      },
      "execution_count": 1396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "JLBlGm6siwXv"
      },
      "execution_count": 1397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"the vocab size or the total word size is {vocab_size}\")\n",
        "print(f\"the maximun length sentence in the data is {maximum_len}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjLm37GEymwg",
        "outputId": "e30ac90c-9b61-4c8d-c32d-f2fad45a97e8"
      },
      "execution_count": 1398,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the vocab size or the total word size is 223\n",
            "the maximun length sentence in the data is 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim=vocab_size,output_dim=50,input_shape=(maximum_len-1,)))\n",
        "model.add(Bidirectional(SimpleRNN(40,activation='relu'))) # Bidirectional RNN\n",
        "model.add(Dense(vocab_size,activation='softmax'))"
      ],
      "metadata": {
        "id": "XLjR2vajiwVD"
      },
      "execution_count": 1399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "X0zG2BBAliMQ",
        "outputId": "e5bfe261-2069-48dd-9f4d-8ebd74d8b081"
      },
      "execution_count": 1400,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_39\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_39\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_41 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m11,150\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m7,280\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m223\u001b[0m)            │        \u001b[38;5;34m18,063\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,150</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,280</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">223</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,063</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,493\u001b[0m (142.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,493</span> (142.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,493\u001b[0m (142.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,493</span> (142.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "az_uQXZ7lmg_"
      },
      "execution_count": 1401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcoJt-k_luZI",
        "outputId": "469bf362-b340-417b-e92f-84f6fed8bb35"
      },
      "execution_count": 1402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.0050 - loss: 5.4059\n",
            "Epoch 2/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0514 - loss: 5.3862\n",
            "Epoch 3/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0749 - loss: 5.3589\n",
            "Epoch 4/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0776 - loss: 5.2717\n",
            "Epoch 5/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0528 - loss: 5.1103\n",
            "Epoch 6/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0574 - loss: 4.9872\n",
            "Epoch 7/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0644 - loss: 4.9758\n",
            "Epoch 8/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0542 - loss: 4.8525\n",
            "Epoch 9/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0721 - loss: 4.8246\n",
            "Epoch 10/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0505 - loss: 4.7898\n",
            "Epoch 11/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0720 - loss: 4.7139\n",
            "Epoch 12/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0657 - loss: 4.5401\n",
            "Epoch 13/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0801 - loss: 4.4844\n",
            "Epoch 14/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0817 - loss: 4.3897\n",
            "Epoch 15/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1105 - loss: 4.1329\n",
            "Epoch 16/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1364 - loss: 3.9342\n",
            "Epoch 17/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2096 - loss: 3.7396\n",
            "Epoch 18/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2053 - loss: 3.5793\n",
            "Epoch 19/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2675 - loss: 3.2129\n",
            "Epoch 20/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3663 - loss: 2.8041\n",
            "Epoch 21/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4752 - loss: 2.3780\n",
            "Epoch 22/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6178 - loss: 1.8489\n",
            "Epoch 23/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7373 - loss: 1.5408\n",
            "Epoch 24/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7157 - loss: 1.2632\n",
            "Epoch 25/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7541 - loss: 1.1092\n",
            "Epoch 26/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 1.0570\n",
            "Epoch 27/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8346 - loss: 0.8075\n",
            "Epoch 28/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8164 - loss: 0.8010\n",
            "Epoch 29/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8647 - loss: 0.6692\n",
            "Epoch 30/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8807 - loss: 0.5916\n",
            "Epoch 31/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8496 - loss: 0.6602\n",
            "Epoch 32/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8639 - loss: 0.5447\n",
            "Epoch 33/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9019 - loss: 0.4817\n",
            "Epoch 34/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.4944\n",
            "Epoch 35/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.4350\n",
            "Epoch 36/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8905 - loss: 0.4306\n",
            "Epoch 37/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9080 - loss: 0.3787\n",
            "Epoch 38/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9119 - loss: 0.3498\n",
            "Epoch 39/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9357 - loss: 0.3244\n",
            "Epoch 40/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9219 - loss: 0.3160\n",
            "Epoch 41/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9157 - loss: 0.3283\n",
            "Epoch 42/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9059 - loss: 0.3386\n",
            "Epoch 43/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9088 - loss: 0.3584\n",
            "Epoch 44/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9023 - loss: 0.3721\n",
            "Epoch 45/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8950 - loss: 0.3639\n",
            "Epoch 46/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8803 - loss: 0.3761\n",
            "Epoch 47/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9194 - loss: 0.3449\n",
            "Epoch 48/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9242 - loss: 0.3465\n",
            "Epoch 49/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9072 - loss: 0.3030\n",
            "Epoch 50/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.3083\n",
            "Epoch 51/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9033 - loss: 0.3000\n",
            "Epoch 52/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9396 - loss: 0.2081\n",
            "Epoch 53/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9261 - loss: 0.2445\n",
            "Epoch 54/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9424 - loss: 0.2241\n",
            "Epoch 55/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.1986\n",
            "Epoch 56/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.1707\n",
            "Epoch 57/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9458 - loss: 0.2043\n",
            "Epoch 58/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9453 - loss: 0.2152\n",
            "Epoch 59/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9420 - loss: 0.1869\n",
            "Epoch 60/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9529 - loss: 0.1582\n",
            "Epoch 61/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9554 - loss: 0.1457\n",
            "Epoch 62/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9584 - loss: 0.1401\n",
            "Epoch 63/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9426 - loss: 0.1994\n",
            "Epoch 64/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1774\n",
            "Epoch 65/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9415 - loss: 0.1832\n",
            "Epoch 66/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9500 - loss: 0.1572\n",
            "Epoch 67/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9420 - loss: 0.1697\n",
            "Epoch 68/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.1757\n",
            "Epoch 69/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9360 - loss: 0.1631\n",
            "Epoch 70/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.1126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f488e66ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 1402
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def predict_next_word(user_text, num_words=9):\n",
        "    \"\"\"\n",
        "    Predicts the next words iteratively based on the given seed text and generates a sequence of words.\n",
        "\n",
        "    Arguments:\n",
        "    user_text -- the initial text (string) to start the prediction\n",
        "    num_words -- the number of words to predict iteratively (default is 10)\n",
        "\n",
        "    Returns:\n",
        "    A string containing the seed text followed by the predicted words.\n",
        "    \"\"\"\n",
        "    # Loop to predict 'num_words' words one by one\n",
        "    for i in range(num_words):\n",
        "        # Step 1: Tokenize the seed text into a sequence of integers\n",
        "        # This converts each word in the seed text into a corresponding integer based on the tokenizer's word index\n",
        "        token_text = tokenizer.texts_to_sequences([user_text])[0]\n",
        "\n",
        "        # Step 2: Pad the tokenized sequence to ensure it matches the model's expected input shape\n",
        "        # Padding ensures that all input sequences are the same length (max_len), and 'pre' means padding is added at the start\n",
        "        padded_token_text = pad_sequences([token_text], maxlen=maximum_len, padding='pre')\n",
        "\n",
        "        # Step 3: Use the model to predict the next word's probabilities\n",
        "        # The model outputs a probability distribution over the vocabulary for the next word\n",
        "        pred = model.predict(padded_token_text)\n",
        "\n",
        "        # Step 4: Get the index of the word with the highest predicted probability\n",
        "        # 'np.argmax' returns the index of the word with the highest probability\n",
        "        pred_word_index = np.argmax(pred)\n",
        "\n",
        "        # Step 5: Retrieve the predicted word from the tokenizer's word index\n",
        "        # We use the word index to map the predicted index back to the corresponding word\n",
        "        pred_word = tokenizer.index_word.get(pred_word_index, None)\n",
        "\n",
        "        # Step 6: Add the predicted word to the seed text\n",
        "        # If a valid word is predicted, append it to the final pred\n",
        "        if pred_word:\n",
        "            user_text = user_text + \" \" + pred_word\n",
        "            print(user_text)  # Print the updated seed text with the new predicted word\n",
        "\n",
        "        # Step 7: Sleep for 2 seconds before predicting the next word\n",
        "        # This introduces a slight delay between predictions to simulate more natural generation\n",
        "        time.sleep(2)\n",
        "\n",
        "    return user_text  # Return the final generated text containing the original seed text and the predicted words\n"
      ],
      "metadata": {
        "id": "8l7y8sH7lwux"
      },
      "execution_count": 1403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Good morning\"\n",
        "generated_text = predict_next_word(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRnd3gdqt8A",
        "outputId": "799c9eba-eba9-474c-8d6a-f2f2a3bcd31e"
      },
      "execution_count": 1404,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "Good morning how\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Good morning how did you sleep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Good morning how did you sleep last\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Good morning how did you sleep last night\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Good morning how did you sleep last night did\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you sleep last night did you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you sleep last night did you have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhaPvG9Mu7Tz"
      },
      "execution_count": 1404,
      "outputs": []
    }
  ]
}