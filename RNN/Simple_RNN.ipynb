{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1252,
      "metadata": {
        "id": "ZCUWTBppfCwY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1253,
      "metadata": {
        "id": "y6OQowK3fTjV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1254,
      "metadata": {
        "id": "o6eOt-BLfXBk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1255,
      "metadata": {
        "id": "_ESQyhj_fdQ1"
      },
      "outputs": [],
      "source": [
        "data = \"\"\"Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
        "Hey there! I was just thinking about you the other day. How have you been doing?\n",
        "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
        "I'm so glad we finally have some time to catch up. What's new in your life?\n",
        "Could you believe how crowded the supermarket was this morning? It was insane!\n",
        "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
        "How was your weekend? Did you end up going to that concert you mentioned?\n",
        "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
        "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
        "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
        "I can't believe how fast this week has gone by. Is it Friday already?\n",
        "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
        "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
        "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
        "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
        "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
        "I love your outfit today! That color really brings out your eyes beautifully.\n",
        "Could you help me with this computer problem? I'm completely stuck right now.\n",
        "How's work been treating you lately? You seem really busy these past few weeks.\n",
        "I'm thinking about redecorating my living room. What do you think would look nice?\n",
        "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
        "I just finished reading the most amazing book. You should definitely check it out.\n",
        "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
        "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
        "How are you feeling today? You look much better than the last time I saw you.\n",
        "I wanted to apologize for missing your birthday party. Something came up at work.\n",
        "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
        "Could you recommend a good mechanic? My car has been making strange noises.\n",
        "I'm really looking forward to the weekend. This work week has been exhausting!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvVG5nKf1RO",
        "outputId": "372c6d0b-d951-460a-c26a-4fb82c7e3c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
            "Hey there! I was just thinking about you the other day. How have you been doing?\n",
            "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
            "I'm so glad we finally have some time to catch up. What's new in your life?\n",
            "Could you believe how crowded the supermarket was this morning? It was insane!\n",
            "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
            "How was your weekend? Did you end up going to that concert you mentioned?\n",
            "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
            "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
            "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
            "I can't believe how fast this week has gone by. Is it Friday already?\n",
            "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
            "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
            "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
            "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
            "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
            "I love your outfit today! That color really brings out your eyes beautifully.\n",
            "Could you help me with this computer problem? I'm completely stuck right now.\n",
            "How's work been treating you lately? You seem really busy these past few weeks.\n",
            "I'm thinking about redecorating my living room. What do you think would look nice?\n",
            "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
            "I just finished reading the most amazing book. You should definitely check it out.\n",
            "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
            "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
            "How are you feeling today? You look much better than the last time I saw you.\n",
            "I wanted to apologize for missing your birthday party. Something came up at work.\n",
            "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
            "Could you recommend a good mechanic? My car has been making strange noises.\n",
            "I'm really looking forward to the weekend. This work week has been exhausting!\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1257,
      "metadata": {
        "id": "7qvmCUaQf2FW"
      },
      "outputs": [],
      "source": [
        "# creating an object of tokenizer class\n",
        "tokenizer = Tokenizer(oov_token='<NOTHING>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1258,
      "metadata": {
        "id": "qyeooTX6f6sG"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TcQK_aBf_z-",
        "outputId": "8850842a-ab66-40d9-fd72-af2b911f42ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<NOTHING>': 1,\n",
              " 'you': 2,\n",
              " 'the': 3,\n",
              " 'i': 4,\n",
              " 'your': 5,\n",
              " 'to': 6,\n",
              " \"i'm\": 7,\n",
              " 'this': 8,\n",
              " 'how': 9,\n",
              " 'have': 10,\n",
              " 'a': 11,\n",
              " 'new': 12,\n",
              " 'it': 13,\n",
              " 'for': 14,\n",
              " 'that': 15,\n",
              " 'really': 16,\n",
              " 'did': 17,\n",
              " 'was': 18,\n",
              " 'just': 19,\n",
              " 'been': 20,\n",
              " 'up': 21,\n",
              " 'weekend': 22,\n",
              " 'today': 23,\n",
              " 'morning': 24,\n",
              " 'last': 25,\n",
              " 'about': 26,\n",
              " 'what': 27,\n",
              " 'so': 28,\n",
              " \"what's\": 29,\n",
              " 'could': 30,\n",
              " 'is': 31,\n",
              " 'do': 32,\n",
              " 'week': 33,\n",
              " 'has': 34,\n",
              " 'on': 35,\n",
              " 'work': 36,\n",
              " 'good': 37,\n",
              " 'thinking': 38,\n",
              " 'day': 39,\n",
              " 'doing': 40,\n",
              " 'had': 41,\n",
              " 'weather': 42,\n",
              " 'we': 43,\n",
              " 'time': 44,\n",
              " 'believe': 45,\n",
              " 'wanted': 46,\n",
              " 'me': 47,\n",
              " 'amazing': 48,\n",
              " 'late': 49,\n",
              " 'like': 50,\n",
              " 'something': 51,\n",
              " 'street': 52,\n",
              " 'nice': 53,\n",
              " 'would': 54,\n",
              " 'restaurant': 55,\n",
              " \"how's\": 56,\n",
              " 'at': 57,\n",
              " 'should': 58,\n",
              " 'are': 59,\n",
              " 'year': 60,\n",
              " 'love': 61,\n",
              " 'out': 62,\n",
              " 'my': 63,\n",
              " 'look': 64,\n",
              " 'reading': 65,\n",
              " 'sleep': 66,\n",
              " 'night': 67,\n",
              " 'any': 68,\n",
              " 'interesting': 69,\n",
              " 'dreams': 70,\n",
              " 'hey': 71,\n",
              " 'there': 72,\n",
              " 'other': 73,\n",
              " 'beautiful': 74,\n",
              " 'outside': 75,\n",
              " 'chance': 76,\n",
              " 'enjoy': 77,\n",
              " 'yet': 78,\n",
              " 'glad': 79,\n",
              " 'finally': 80,\n",
              " 'some': 81,\n",
              " 'catch': 82,\n",
              " 'in': 83,\n",
              " 'life': 84,\n",
              " 'crowded': 85,\n",
              " 'supermarket': 86,\n",
              " 'insane': 87,\n",
              " 'say': 88,\n",
              " 'thank': 89,\n",
              " 'again': 90,\n",
              " 'helping': 91,\n",
              " 'move': 92,\n",
              " \"you're\": 93,\n",
              " 'end': 94,\n",
              " 'going': 95,\n",
              " 'concert': 96,\n",
              " 'mentioned': 97,\n",
              " 'sorry': 98,\n",
              " 'running': 99,\n",
              " 'traffic': 100,\n",
              " 'absolutely': 101,\n",
              " 'terrible': 102,\n",
              " 'feel': 103,\n",
              " 'having': 104,\n",
              " 'lunch': 105,\n",
              " 'craving': 106,\n",
              " 'spicy': 107,\n",
              " 'myself': 108,\n",
              " 'seen': 109,\n",
              " 'coffee': 110,\n",
              " 'shop': 111,\n",
              " 'opened': 112,\n",
              " 'down': 113,\n",
              " 'looks': 114,\n",
              " \"can't\": 115,\n",
              " 'fast': 116,\n",
              " 'gone': 117,\n",
              " 'by': 118,\n",
              " 'friday': 119,\n",
              " 'already': 120,\n",
              " 'grab': 121,\n",
              " 'dinner': 122,\n",
              " 'sometime': 123,\n",
              " 'know': 124,\n",
              " 'great': 125,\n",
              " 'family': 126,\n",
              " 'heard': 127,\n",
              " 'sister': 128,\n",
              " 'baby': 129,\n",
              " 'congratulations': 130,\n",
              " 'tired': 131,\n",
              " 'stayed': 132,\n",
              " 'way': 133,\n",
              " 'too': 134,\n",
              " 'watching': 135,\n",
              " 'show': 136,\n",
              " 'netflix': 137,\n",
              " 'hear': 138,\n",
              " 'big': 139,\n",
              " 'sale': 140,\n",
              " 'happening': 141,\n",
              " 'mall': 142,\n",
              " 'go': 143,\n",
              " 'plan': 144,\n",
              " 'holidays': 145,\n",
              " 'traveling': 146,\n",
              " 'anywhere': 147,\n",
              " 'exciting': 148,\n",
              " 'outfit': 149,\n",
              " 'color': 150,\n",
              " 'brings': 151,\n",
              " 'eyes': 152,\n",
              " 'beautifully': 153,\n",
              " 'help': 154,\n",
              " 'with': 155,\n",
              " 'computer': 156,\n",
              " 'problem': 157,\n",
              " 'completely': 158,\n",
              " 'stuck': 159,\n",
              " 'right': 160,\n",
              " 'now': 161,\n",
              " 'treating': 162,\n",
              " 'lately': 163,\n",
              " 'seem': 164,\n",
              " 'busy': 165,\n",
              " 'these': 166,\n",
              " 'past': 167,\n",
              " 'few': 168,\n",
              " 'weeks': 169,\n",
              " 'redecorating': 170,\n",
              " 'living': 171,\n",
              " 'room': 172,\n",
              " 'think': 173,\n",
              " 'forecast': 174,\n",
              " 'says': 175,\n",
              " 'might': 176,\n",
              " 'rain': 177,\n",
              " 'tomorrow': 178,\n",
              " \"don't\": 179,\n",
              " 'forget': 180,\n",
              " 'umbrella': 181,\n",
              " 'finished': 182,\n",
              " 'most': 183,\n",
              " 'book': 184,\n",
              " 'definitely': 185,\n",
              " 'check': 186,\n",
              " 'tried': 187,\n",
              " 'italian': 188,\n",
              " 'main': 189,\n",
              " 'pasta': 190,\n",
              " 'incredible': 191,\n",
              " 'excited': 192,\n",
              " 'summer': 193,\n",
              " 'vacation': 194,\n",
              " \"we're\": 195,\n",
              " 'planning': 196,\n",
              " 'visit': 197,\n",
              " 'europe': 198,\n",
              " 'feeling': 199,\n",
              " 'much': 200,\n",
              " 'better': 201,\n",
              " 'than': 202,\n",
              " 'saw': 203,\n",
              " 'apologize': 204,\n",
              " 'missing': 205,\n",
              " 'birthday': 206,\n",
              " 'party': 207,\n",
              " 'came': 208,\n",
              " 'favorite': 209,\n",
              " 'thing': 210,\n",
              " 'lazy': 211,\n",
              " 'sunday': 212,\n",
              " 'afternoon': 213,\n",
              " 'recommend': 214,\n",
              " 'mechanic': 215,\n",
              " 'car': 216,\n",
              " 'making': 217,\n",
              " 'strange': 218,\n",
              " 'noises': 219,\n",
              " 'looking': 220,\n",
              " 'forward': 221,\n",
              " 'exhausting': 222}"
            ]
          },
          "execution_count": 1259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the word indes\n",
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfLz4PogCOO",
        "outputId": "36bb3a19-027a-40af-ce74-dc2aca240063"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['<NOTHING>', 'you', 'the', 'i', 'your', 'to', \"i'm\", 'this', 'how', 'have', 'a', 'new', 'it', 'for', 'that', 'really', 'did', 'was', 'just', 'been', 'up', 'weekend', 'today', 'morning', 'last', 'about', 'what', 'so', \"what's\", 'could', 'is', 'do', 'week', 'has', 'on', 'work', 'good', 'thinking', 'day', 'doing', 'had', 'weather', 'we', 'time', 'believe', 'wanted', 'me', 'amazing', 'late', 'like', 'something', 'street', 'nice', 'would', 'restaurant', \"how's\", 'at', 'should', 'are', 'year', 'love', 'out', 'my', 'look', 'reading', 'sleep', 'night', 'any', 'interesting', 'dreams', 'hey', 'there', 'other', 'beautiful', 'outside', 'chance', 'enjoy', 'yet', 'glad', 'finally', 'some', 'catch', 'in', 'life', 'crowded', 'supermarket', 'insane', 'say', 'thank', 'again', 'helping', 'move', \"you're\", 'end', 'going', 'concert', 'mentioned', 'sorry', 'running', 'traffic', 'absolutely', 'terrible', 'feel', 'having', 'lunch', 'craving', 'spicy', 'myself', 'seen', 'coffee', 'shop', 'opened', 'down', 'looks', \"can't\", 'fast', 'gone', 'by', 'friday', 'already', 'grab', 'dinner', 'sometime', 'know', 'great', 'family', 'heard', 'sister', 'baby', 'congratulations', 'tired', 'stayed', 'way', 'too', 'watching', 'show', 'netflix', 'hear', 'big', 'sale', 'happening', 'mall', 'go', 'plan', 'holidays', 'traveling', 'anywhere', 'exciting', 'outfit', 'color', 'brings', 'eyes', 'beautifully', 'help', 'with', 'computer', 'problem', 'completely', 'stuck', 'right', 'now', 'treating', 'lately', 'seem', 'busy', 'these', 'past', 'few', 'weeks', 'redecorating', 'living', 'room', 'think', 'forecast', 'says', 'might', 'rain', 'tomorrow', \"don't\", 'forget', 'umbrella', 'finished', 'most', 'book', 'definitely', 'check', 'tried', 'italian', 'main', 'pasta', 'incredible', 'excited', 'summer', 'vacation', \"we're\", 'planning', 'visit', 'europe', 'feeling', 'much', 'better', 'than', 'saw', 'apologize', 'missing', 'birthday', 'party', 'came', 'favorite', 'thing', 'lazy', 'sunday', 'afternoon', 'recommend', 'mechanic', 'car', 'making', 'strange', 'noises', 'looking', 'forward', 'exhausting'])"
            ]
          },
          "execution_count": 1260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the words\n",
        "tokenizer.word_index.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amN1KgkvggiH",
        "outputId": "b9e12f00-ee87-4df8-ce5d-2508788eff9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222])"
            ]
          },
          "execution_count": 1261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the values\n",
        "tokenizer.word_index.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg3qV7JlkKPH",
        "outputId": "758aff1b-7e08-474f-87f7-831d786ae92a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "execution_count": 1262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.word_index.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svfldnylgi1O",
        "outputId": "def89e62-bb2b-4987-fc29-cd6a286568ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70]\n",
            "[71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40]\n",
            "[27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78]\n",
            "[7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84]\n",
            "[30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87]\n",
            "[4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48]\n",
            "[9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97]\n",
            "[7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24]\n",
            "[27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108]\n",
            "[10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53]\n",
            "[4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120]\n",
            "[54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55]\n",
            "[56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130]\n",
            "[7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137]\n",
            "[17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143]\n",
            "[29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60]\n",
            "[4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153]\n",
            "[30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161]\n",
            "[56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169]\n",
            "[7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53]\n",
            "[3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181]\n",
            "[4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62]\n",
            "[10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191]\n",
            "[7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60]\n",
            "[9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2]\n",
            "[4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36]\n",
            "[29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65]\n",
            "[30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219]\n",
            "[7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]\n"
          ]
        }
      ],
      "source": [
        "# convert the sentences based on the text sequence\n",
        "for sentence in data.split(\"\\n\"):\n",
        "  if sentence.strip():\n",
        "    print(tokenizer.texts_to_sequences([sentence])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1264,
      "metadata": {
        "id": "GvTkEIJWhFbf"
      },
      "outputs": [],
      "source": [
        "# making the input and the output sequence\n",
        "input_sequences = []\n",
        "for sentence in data.split('\\n'):\n",
        "  if sentence.strip():\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] # convert the sentences based on the text sequence\n",
        "\n",
        "    for i in range(1,len(tokenized_sentence)):\n",
        "      input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4B1mrA_-iU7I",
        "outputId": "71bff6ad-2834-4590-c0c0-173791b0a334"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nso if X = 36 then y = 23\\nif X = 36,23 then y = 8\\n'"
            ]
          },
          "execution_count": 1265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for 36 the next word will be 23\n",
        "# for 23 and 36 the next word will be 8\n",
        "\n",
        "\"\"\"\n",
        "so if X = 36 then y = 23\n",
        "if X = 36,23 then y = 8\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOi9rLLSiR4X",
        "outputId": "79ac7581-6602-4c8b-da5b-49caf837cee7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[37, 24],\n",
              " [37, 24, 9],\n",
              " [37, 24, 9, 17],\n",
              " [37, 24, 9, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66],\n",
              " [37, 24, 9, 17, 2, 66, 25],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70],\n",
              " [71, 72],\n",
              " [71, 72, 4],\n",
              " [71, 72, 4, 18],\n",
              " [71, 72, 4, 18, 19],\n",
              " [71, 72, 4, 18, 19, 38],\n",
              " [71, 72, 4, 18, 19, 38, 26],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40],\n",
              " [27, 11],\n",
              " [27, 11, 74],\n",
              " [27, 11, 74, 39],\n",
              " [27, 11, 74, 39, 75],\n",
              " [27, 11, 74, 39, 75, 10],\n",
              " [27, 11, 74, 39, 75, 10, 2],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78],\n",
              " [7, 28],\n",
              " [7, 28, 79],\n",
              " [7, 28, 79, 43],\n",
              " [7, 28, 79, 43, 80],\n",
              " [7, 28, 79, 43, 80, 10],\n",
              " [7, 28, 79, 43, 80, 10, 81],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84],\n",
              " [30, 2],\n",
              " [30, 2, 45],\n",
              " [30, 2, 45, 9],\n",
              " [30, 2, 45, 9, 85],\n",
              " [30, 2, 45, 9, 85, 3],\n",
              " [30, 2, 45, 9, 85, 3, 86],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87],\n",
              " [4, 19],\n",
              " [4, 19, 46],\n",
              " [4, 19, 46, 6],\n",
              " [4, 19, 46, 6, 88],\n",
              " [4, 19, 46, 6, 88, 89],\n",
              " [4, 19, 46, 6, 88, 89, 2],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48],\n",
              " [9, 18],\n",
              " [9, 18, 5],\n",
              " [9, 18, 5, 22],\n",
              " [9, 18, 5, 22, 17],\n",
              " [9, 18, 5, 22, 17, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97],\n",
              " [7, 16],\n",
              " [7, 16, 98],\n",
              " [7, 16, 98, 7],\n",
              " [7, 16, 98, 7, 99],\n",
              " [7, 16, 98, 7, 99, 49],\n",
              " [7, 16, 98, 7, 99, 49, 100],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24],\n",
              " [27, 32],\n",
              " [27, 32, 2],\n",
              " [27, 32, 2, 103],\n",
              " [27, 32, 2, 103, 50],\n",
              " [27, 32, 2, 103, 50, 104],\n",
              " [27, 32, 2, 103, 50, 104, 14],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108],\n",
              " [10, 2],\n",
              " [10, 2, 109],\n",
              " [10, 2, 109, 3],\n",
              " [10, 2, 109, 3, 12],\n",
              " [10, 2, 109, 3, 12, 110],\n",
              " [10, 2, 109, 3, 12, 110, 111],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53],\n",
              " [4, 115],\n",
              " [4, 115, 45],\n",
              " [4, 115, 45, 9],\n",
              " [4, 115, 45, 9, 116],\n",
              " [4, 115, 45, 9, 116, 8],\n",
              " [4, 115, 45, 9, 116, 8, 33],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120],\n",
              " [54, 2],\n",
              " [54, 2, 50],\n",
              " [54, 2, 50, 6],\n",
              " [54, 2, 50, 6, 121],\n",
              " [54, 2, 50, 6, 121, 122],\n",
              " [54, 2, 50, 6, 121, 122, 123],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55],\n",
              " [56, 5],\n",
              " [56, 5, 126],\n",
              " [56, 5, 126, 40],\n",
              " [56, 5, 126, 40, 4],\n",
              " [56, 5, 126, 40, 4, 127],\n",
              " [56, 5, 126, 40, 4, 127, 5],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130],\n",
              " [7, 28],\n",
              " [7, 28, 131],\n",
              " [7, 28, 131, 23],\n",
              " [7, 28, 131, 23, 4],\n",
              " [7, 28, 131, 23, 4, 132],\n",
              " [7, 28, 131, 23, 4, 132, 21],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137],\n",
              " [17, 2],\n",
              " [17, 2, 138],\n",
              " [17, 2, 138, 26],\n",
              " [17, 2, 138, 26, 3],\n",
              " [17, 2, 138, 26, 3, 139],\n",
              " [17, 2, 138, 26, 3, 139, 140],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143],\n",
              " [29, 5],\n",
              " [29, 5, 144],\n",
              " [29, 5, 144, 14],\n",
              " [29, 5, 144, 14, 3],\n",
              " [29, 5, 144, 14, 3, 145],\n",
              " [29, 5, 144, 14, 3, 145, 59],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60],\n",
              " [4, 61],\n",
              " [4, 61, 5],\n",
              " [4, 61, 5, 149],\n",
              " [4, 61, 5, 149, 23],\n",
              " [4, 61, 5, 149, 23, 15],\n",
              " [4, 61, 5, 149, 23, 15, 150],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153],\n",
              " [30, 2],\n",
              " [30, 2, 154],\n",
              " [30, 2, 154, 47],\n",
              " [30, 2, 154, 47, 155],\n",
              " [30, 2, 154, 47, 155, 8],\n",
              " [30, 2, 154, 47, 155, 8, 156],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161],\n",
              " [56, 36],\n",
              " [56, 36, 20],\n",
              " [56, 36, 20, 162],\n",
              " [56, 36, 20, 162, 2],\n",
              " [56, 36, 20, 162, 2, 163],\n",
              " [56, 36, 20, 162, 2, 163, 2],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169],\n",
              " [7, 38],\n",
              " [7, 38, 26],\n",
              " [7, 38, 26, 170],\n",
              " [7, 38, 26, 170, 63],\n",
              " [7, 38, 26, 170, 63, 171],\n",
              " [7, 38, 26, 170, 63, 171, 172],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53],\n",
              " [3, 42],\n",
              " [3, 42, 174],\n",
              " [3, 42, 174, 175],\n",
              " [3, 42, 174, 175, 13],\n",
              " [3, 42, 174, 175, 13, 176],\n",
              " [3, 42, 174, 175, 13, 176, 177],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181],\n",
              " [4, 19],\n",
              " [4, 19, 182],\n",
              " [4, 19, 182, 65],\n",
              " [4, 19, 182, 65, 3],\n",
              " [4, 19, 182, 65, 3, 183],\n",
              " [4, 19, 182, 65, 3, 183, 48],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62],\n",
              " [10, 2],\n",
              " [10, 2, 187],\n",
              " [10, 2, 187, 15],\n",
              " [10, 2, 187, 15, 12],\n",
              " [10, 2, 187, 15, 12, 188],\n",
              " [10, 2, 187, 15, 12, 188, 55],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191],\n",
              " [7, 28],\n",
              " [7, 28, 192],\n",
              " [7, 28, 192, 14],\n",
              " [7, 28, 192, 14, 193],\n",
              " [7, 28, 192, 14, 193, 194],\n",
              " [7, 28, 192, 14, 193, 194, 195],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60],\n",
              " [9, 59],\n",
              " [9, 59, 2],\n",
              " [9, 59, 2, 199],\n",
              " [9, 59, 2, 199, 23],\n",
              " [9, 59, 2, 199, 23, 2],\n",
              " [9, 59, 2, 199, 23, 2, 64],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2],\n",
              " [4, 46],\n",
              " [4, 46, 6],\n",
              " [4, 46, 6, 204],\n",
              " [4, 46, 6, 204, 14],\n",
              " [4, 46, 6, 204, 14, 205],\n",
              " [4, 46, 6, 204, 14, 205, 5],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36],\n",
              " [29, 5],\n",
              " [29, 5, 209],\n",
              " [29, 5, 209, 210],\n",
              " [29, 5, 209, 210, 6],\n",
              " [29, 5, 209, 210, 6, 32],\n",
              " [29, 5, 209, 210, 6, 32, 35],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65],\n",
              " [30, 2],\n",
              " [30, 2, 214],\n",
              " [30, 2, 214, 11],\n",
              " [30, 2, 214, 11, 37],\n",
              " [30, 2, 214, 11, 37, 215],\n",
              " [30, 2, 214, 11, 37, 215, 63],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219],\n",
              " [7, 16],\n",
              " [7, 16, 220],\n",
              " [7, 16, 220, 221],\n",
              " [7, 16, 220, 221, 6],\n",
              " [7, 16, 220, 221, 6, 3],\n",
              " [7, 16, 220, 221, 6, 3, 22],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]]"
            ]
          },
          "execution_count": 1266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIjtdOcOiw5f",
        "outputId": "491745af-f609-4d24-ffb2-d7a75fa69cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 1267,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the maximum length\n",
        "maximum_len = max([len(x) for x in input_sequences])\n",
        "maximum_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1268,
      "metadata": {
        "id": "xbAoCv00iw2X"
      },
      "outputs": [],
      "source": [
        "# padding (pre padding)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = maximum_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQFbSHEciw0G",
        "outputId": "8804ea70-62bb-4ac3-a9af-b3134aa57df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  37,  24],\n",
              "       [  0,   0,   0, ...,  37,  24,   9],\n",
              "       [  0,   0,   0, ...,  24,   9,  17],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  36,  33,  34],\n",
              "       [  0,   0,   0, ...,  33,  34,  20],\n",
              "       [  0,   0,   0, ...,  34,  20, 222]], dtype=int32)"
            ]
          },
          "execution_count": 1269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2CWNeoJiwwX",
        "outputId": "845a15bc-ebcf-43a5-c4de-779684fa0b2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 16)"
            ]
          },
          "execution_count": 1270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TtGo25xiwsI",
        "outputId": "47660f95-f089-4b1d-acd8-333126aa6c23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0, 37],\n",
              "       [ 0,  0,  0, ...,  0, 37, 24],\n",
              "       [ 0,  0,  0, ..., 37, 24,  9],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  8, 36, 33],\n",
              "       [ 0,  0,  0, ..., 36, 33, 34],\n",
              "       [ 0,  0,  0, ..., 33, 34, 20]], dtype=int32)"
            ]
          },
          "execution_count": 1271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6DaSq8j0L2",
        "outputId": "9582c740-7963-4d8a-d1d3-aed6bb11f71c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 15)"
            ]
          },
          "execution_count": 1272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxZQv2UGiwpb",
        "outputId": "5550c174-e0d4-4329-ffa3-53fd48514a98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 24,   9,  17,   2,  66,  25,  67,  17,   2,  10,  68,  69,  70,\n",
              "        72,   4,  18,  19,  38,  26,   2,   3,  73,  39,   9,  10,   2,\n",
              "        20,  40,  11,  74,  39,  75,  10,   2,  41,  11,  76,   6,  77,\n",
              "         3,  42,  78,  28,  79,  43,  80,  10,  81,  44,   6,  82,  21,\n",
              "        29,  12,  83,   5,  84,   2,  45,   9,  85,   3,  86,  18,   8,\n",
              "        24,  13,  18,  87,  19,  46,   6,  88,  89,   2,  90,  14,  91,\n",
              "        47,  92,  25,  22,  93,  48,  18,   5,  22,  17,   2,  94,  21,\n",
              "        95,   6,  15,  96,   2,  97,  16,  98,   7,  99,  49, 100,  31,\n",
              "       101, 102,   8,  24,  32,   2, 103,  50, 104,  14, 105,  23,   7,\n",
              "       106,  51, 107, 108,   2, 109,   3,  12, 110, 111,  15, 112, 113,\n",
              "         3,  52,  13, 114,  16,  53, 115,  45,   9, 116,   8,  33,  34,\n",
              "       117, 118,  31,  13, 119, 120,   2,  50,   6, 121, 122, 123,   8,\n",
              "        33,   4, 124,  11, 125,  12,  55,   5, 126,  40,   4, 127,   5,\n",
              "       128,  19,  41,  11, 129, 130,  28, 131,  23,   4, 132,  21, 133,\n",
              "       134,  49, 135,  15,  12, 136,  35, 137,   2, 138,  26,   3, 139,\n",
              "       140, 141,  57,   3, 142,   8,  22,  43,  58, 143,   5, 144,  14,\n",
              "         3, 145,  59,   2, 146, 147, 148,   8,  60,  61,   5, 149,  23,\n",
              "        15, 150,  16, 151,  62,   5, 152, 153,   2, 154,  47, 155,   8,\n",
              "       156, 157,   7, 158, 159, 160, 161,  36,  20, 162,   2, 163,   2,\n",
              "       164,  16, 165, 166, 167, 168, 169,  38,  26, 170,  63, 171, 172,\n",
              "        27,  32,   2, 173,  54,  64,  53,  42, 174, 175,  13, 176, 177,\n",
              "       178, 179, 180,   5, 181,  19, 182,  65,   3, 183,  48, 184,   2,\n",
              "        58, 185, 186,  13,  62,   2, 187,  15,  12, 188,  55,  35, 189,\n",
              "        52,   3, 190,  31, 191,  28, 192,  14, 193, 194, 195, 196,   6,\n",
              "       197, 198,   8,  60,  59,   2, 199,  23,   2,  64, 200, 201, 202,\n",
              "         3,  25,  44,   4, 203,   2,  46,   6, 204,  14, 205,   5, 206,\n",
              "       207,  51, 208,  21,  57,  36,   5, 209, 210,   6,  32,  35,  11,\n",
              "       211, 212, 213,   4,  61,  65,   2, 214,  11,  37, 215,  63, 216,\n",
              "        34,  20, 217, 218, 219,  16, 220, 221,   6,   3,  22,   8,  36,\n",
              "        33,  34,  20, 222], dtype=int32)"
            ]
          },
          "execution_count": 1273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = padded_input_sequences[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1274,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehDrOC6vjyRI",
        "outputId": "b237b0f9-3768-4df5-fdde-34ceaacd745f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381,)"
            ]
          },
          "execution_count": 1274,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2jsydhpZzI",
        "outputId": "048c4f62-3198-4c97-ade8-d63c863079d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "execution_count": 1275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) +1 # +1 fo including the zero index\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1276,
      "metadata": {
        "id": "rWhaAC4Xj8cw"
      },
      "outputs": [],
      "source": [
        "# applying One-Hot-Encoding on the traget column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1277,
      "metadata": {
        "id": "wnbc0HJQiwnG"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y,num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYe6jmOviwkR",
        "outputId": "f0b98a1e-3eb0-4a66-f18d-33dd223d48fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 223)"
            ]
          },
          "execution_count": 1278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmgP50d0muMo",
        "outputId": "5ab451f3-9957-429a-e07c-b4aaad084149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "223\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.word_index) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1280,
      "metadata": {
        "id": "3R4qAkAwiwcm"
      },
      "outputs": [],
      "source": [
        "# makin the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1281,
      "metadata": {
        "id": "JLBlGm6siwXv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjLm37GEymwg",
        "outputId": "604af900-cd7c-48a4-af70-d2069bfc8f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the vocab size is 223\n",
            "the maximun length is 16\n"
          ]
        }
      ],
      "source": [
        "print(f\"the vocab size is {vocab_size}\")\n",
        "print(f\"the maximun length is {maximum_len}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "FOR Embedding layer:\n",
        "    input_dim:\n",
        "    - Meaning: This is the size of the vocabulary, i.e., the number of unique words or tokens in your dataset\n",
        "\n",
        "    output_dim:\n",
        "    - Meaning: This specifies the dimensionality of the output embedding vectors for each word.\n",
        "\n",
        "    input_length:\n",
        "    - Meaning: This specifies the length of the input sequences to the Embedding layer (i.e., the max number of words per sequence).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1283,
      "metadata": {
        "id": "XLjR2vajiwVD"
      },
      "outputs": [],
      "source": [
        "model.add(Embedding(input_dim=vocab_size,output_dim=50,input_shape=(maximum_len-1,)))\n",
        "model.add(SimpleRNN(40,activation='relu'))\n",
        "model.add(Dense(vocab_size,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "X0zG2BBAliMQ",
        "outputId": "d8061533-c074-4b72-a6ba-8a5b5e714d98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_36\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_36\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,150</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">223</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,143</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_37 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m11,150\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_35 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │         \u001b[38;5;34m3,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m223\u001b[0m)            │         \u001b[38;5;34m9,143\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,933</span> (93.49 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,933\u001b[0m (93.49 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,933</span> (93.49 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,933\u001b[0m (93.49 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1285,
      "metadata": {
        "id": "az_uQXZ7lmg_"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcoJt-k_luZI",
        "outputId": "125e59cd-7f3b-45af-c820-65176b274c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0263 - loss: 5.4035\n",
            "Epoch 2/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0499 - loss: 5.3659\n",
            "Epoch 3/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0780 - loss: 5.2297\n",
            "Epoch 4/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0792 - loss: 5.1304\n",
            "Epoch 5/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0494 - loss: 5.1292\n",
            "Epoch 6/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0599 - loss: 4.9807\n",
            "Epoch 7/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0697 - loss: 4.9290\n",
            "Epoch 8/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0491 - loss: 4.9065\n",
            "Epoch 9/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0807 - loss: 4.7266\n",
            "Epoch 10/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0647 - loss: 4.7572\n",
            "Epoch 11/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0777 - loss: 4.6253\n",
            "Epoch 12/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0763 - loss: 4.6016\n",
            "Epoch 13/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0960 - loss: 4.3607\n",
            "Epoch 14/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0827 - loss: 4.4040\n",
            "Epoch 15/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0876 - loss: 4.3731\n",
            "Epoch 16/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1014 - loss: 4.1282\n",
            "Epoch 17/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1269 - loss: 3.9932\n",
            "Epoch 18/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1515 - loss: 3.8315\n",
            "Epoch 19/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1783 - loss: 3.6575\n",
            "Epoch 20/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2846 - loss: 3.3378\n",
            "Epoch 21/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2869 - loss: 3.1772\n",
            "Epoch 22/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3723 - loss: 2.7409\n",
            "Epoch 23/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4939 - loss: 2.5752\n",
            "Epoch 24/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5014 - loss: 2.2369\n",
            "Epoch 25/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5518 - loss: 2.0240\n",
            "Epoch 26/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5535 - loss: 1.9382\n",
            "Epoch 27/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6443 - loss: 1.5384\n",
            "Epoch 28/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7072 - loss: 1.4524\n",
            "Epoch 29/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7303 - loss: 1.3321\n",
            "Epoch 30/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6810 - loss: 1.4128\n",
            "Epoch 31/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7388 - loss: 1.2264\n",
            "Epoch 32/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8083 - loss: 1.0469\n",
            "Epoch 33/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7379 - loss: 1.1477\n",
            "Epoch 34/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7754 - loss: 0.9707\n",
            "Epoch 35/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8072 - loss: 0.9283\n",
            "Epoch 36/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7928 - loss: 0.8944\n",
            "Epoch 37/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8158 - loss: 0.7888\n",
            "Epoch 38/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8641 - loss: 0.7216\n",
            "Epoch 39/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8721 - loss: 0.6682\n",
            "Epoch 40/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8455 - loss: 0.7245\n",
            "Epoch 41/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8458 - loss: 0.6705\n",
            "Epoch 42/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8570 - loss: 0.6976\n",
            "Epoch 43/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.6591\n",
            "Epoch 44/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8435 - loss: 0.6696\n",
            "Epoch 45/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8680 - loss: 0.6012\n",
            "Epoch 46/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8788 - loss: 0.5369\n",
            "Epoch 47/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.4771\n",
            "Epoch 48/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.5257\n",
            "Epoch 49/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8857 - loss: 0.5474\n",
            "Epoch 50/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8872 - loss: 0.4742\n",
            "Epoch 51/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.4400\n",
            "Epoch 52/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9007 - loss: 0.5135\n",
            "Epoch 53/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9273 - loss: 0.3926\n",
            "Epoch 54/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9329 - loss: 0.4015\n",
            "Epoch 55/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9070 - loss: 0.3747\n",
            "Epoch 56/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.3756\n",
            "Epoch 57/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9095 - loss: 0.3772\n",
            "Epoch 58/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.3944\n",
            "Epoch 59/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.4095\n",
            "Epoch 60/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9036 - loss: 0.3896\n",
            "Epoch 61/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9192 - loss: 0.3950\n",
            "Epoch 62/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.3896\n",
            "Epoch 63/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9015 - loss: 0.4126\n",
            "Epoch 64/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9210 - loss: 0.3407\n",
            "Epoch 65/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.3223\n",
            "Epoch 66/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.2699\n",
            "Epoch 67/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9295 - loss: 0.2866\n",
            "Epoch 68/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.2923\n",
            "Epoch 69/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.3262\n",
            "Epoch 70/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9319 - loss: 0.2653\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f48a887980>"
            ]
          },
          "execution_count": 1286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X,y,epochs=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1287,
      "metadata": {
        "id": "8l7y8sH7lwux"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def predict_next_word(user_text, num_words=9):\n",
        "    \"\"\"\n",
        "    Predicts the next words iteratively based on the given seed text and generates a sequence of words.\n",
        "\n",
        "    Arguments:\n",
        "    user_text -- the initial text (string) to start the prediction\n",
        "    num_words -- the number of words to predict iteratively (default is 10)\n",
        "\n",
        "    Returns:\n",
        "    A string containing the seed text followed by the predicted words.\n",
        "    \"\"\"\n",
        "    # Loop to predict 'num_words' words one by one\n",
        "    for i in range(num_words):\n",
        "        # Step 1: Tokenize the seed text into a sequence of integers\n",
        "        # This converts each word in the seed text into a corresponding integer based on the tokenizer's word index\n",
        "        token_text = tokenizer.texts_to_sequences([user_text])[0]\n",
        "\n",
        "        # Step 2: Pad the tokenized sequence to ensure it matches the model's expected input shape\n",
        "        # Padding ensures that all input sequences are the same length (max_len), and 'pre' means padding is added at the start\n",
        "        padded_token_text = pad_sequences([token_text], maxlen=maximum_len, padding='pre')\n",
        "\n",
        "        # Step 3: Use the model to predict the next word's probabilities\n",
        "        # The model outputs a probability distribution over the vocabulary for the next word\n",
        "        pred = model.predict(padded_token_text)\n",
        "\n",
        "        # Step 4: Get the index of the word with the highest predicted probability\n",
        "        # 'np.argmax' returns the index of the word with the highest probability\n",
        "        pred_word_index = np.argmax(pred)\n",
        "\n",
        "        # Step 5: Retrieve the predicted word from the tokenizer's word index\n",
        "        # We use the word index to map the predicted index back to the corresponding word\n",
        "        pred_word = tokenizer.index_word.get(pred_word_index, None)\n",
        "\n",
        "        # Step 6: Add the predicted word to the seed text\n",
        "        # If a valid word is predicted, append it to the final pred\n",
        "        if pred_word:\n",
        "            user_text = user_text + \" \" + pred_word\n",
        "            print(user_text)  # Print the updated seed text with the new predicted word\n",
        "\n",
        "        # Step 7: Sleep for 2 seconds before predicting the next word\n",
        "        # This introduces a slight delay between predictions to simulate more natural generation\n",
        "        time.sleep(2)\n",
        "\n",
        "    return user_text  # Return the final generated text containing the original seed text and the predicted words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRnd3gdqt8A",
        "outputId": "17e8b18f-0aee-4351-b605-ecb20bdf3ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "What a beautiful\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "What a beautiful day\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "What a beautiful day outside\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "What a beautiful day outside have\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "What a beautiful day outside have you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "What a beautiful day outside have you had\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "What a beautiful day outside have you had a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "What a beautiful day outside have you had a chance\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "What a beautiful day outside have you had a chance to\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"What a\"\n",
        "generated_text = predict_next_word(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1288,
      "metadata": {
        "id": "yhaPvG9Mu7Tz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
