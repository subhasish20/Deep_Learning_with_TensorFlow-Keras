{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1368,
      "metadata": {
        "id": "ZCUWTBppfCwY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1369,
      "metadata": {
        "id": "y6OQowK3fTjV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1370,
      "metadata": {
        "id": "o6eOt-BLfXBk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding,Bidirectional\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1371,
      "metadata": {
        "id": "_ESQyhj_fdQ1"
      },
      "outputs": [],
      "source": [
        "data = \"\"\"Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
        "Hey there! I was just thinking about you the other day. How have you been doing?\n",
        "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
        "I'm so glad we finally have some time to catch up. What's new in your life?\n",
        "Could you believe how crowded the supermarket was this morning? It was insane!\n",
        "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
        "How was your weekend? Did you end up going to that concert you mentioned?\n",
        "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
        "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
        "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
        "I can't believe how fast this week has gone by. Is it Friday already?\n",
        "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
        "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
        "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
        "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
        "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
        "I love your outfit today! That color really brings out your eyes beautifully.\n",
        "Could you help me with this computer problem? I'm completely stuck right now.\n",
        "How's work been treating you lately? You seem really busy these past few weeks.\n",
        "I'm thinking about redecorating my living room. What do you think would look nice?\n",
        "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
        "I just finished reading the most amazing book. You should definitely check it out.\n",
        "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
        "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
        "How are you feeling today? You look much better than the last time I saw you.\n",
        "I wanted to apologize for missing your birthday party. Something came up at work.\n",
        "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
        "Could you recommend a good mechanic? My car has been making strange noises.\n",
        "I'm really looking forward to the weekend. This work week has been exhausting!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1372,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvVG5nKf1RO",
        "outputId": "b306a968-ce59-40c1-e950-de6dc2da639a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good morning! How did you sleep last night? Did you have any interesting dreams?\n",
            "Hey there! I was just thinking about you the other day. How have you been doing?\n",
            "What a beautiful day outside! Have you had a chance to enjoy the weather yet?\n",
            "I'm so glad we finally have some time to catch up. What's new in your life?\n",
            "Could you believe how crowded the supermarket was this morning? It was insane!\n",
            "I just wanted to say thank you again for helping me move last weekend. You're amazing!\n",
            "How was your weekend? Did you end up going to that concert you mentioned?\n",
            "I'm really sorry I'm running late. Traffic is absolutely terrible this morning.\n",
            "What do you feel like having for lunch today? I'm craving something spicy myself.\n",
            "Have you seen the new coffee shop that opened down the street? It looks really nice.\n",
            "I can't believe how fast this week has gone by. Is it Friday already?\n",
            "Would you like to grab dinner sometime this week? I know a great new restaurant.\n",
            "How's your family doing? I heard your sister just had a baby. Congratulations!\n",
            "I'm so tired today. I stayed up way too late watching that new show on Netflix.\n",
            "Did you hear about the big sale happening at the mall this weekend? We should go!\n",
            "What's your plan for the holidays? Are you traveling anywhere exciting this year?\n",
            "I love your outfit today! That color really brings out your eyes beautifully.\n",
            "Could you help me with this computer problem? I'm completely stuck right now.\n",
            "How's work been treating you lately? You seem really busy these past few weeks.\n",
            "I'm thinking about redecorating my living room. What do you think would look nice?\n",
            "The weather forecast says it might rain tomorrow. Don't forget your umbrella!\n",
            "I just finished reading the most amazing book. You should definitely check it out.\n",
            "Have you tried that new Italian restaurant on Main Street? The pasta is incredible!\n",
            "I'm so excited for summer vacation. We're planning to visit Europe this year!\n",
            "How are you feeling today? You look much better than the last time I saw you.\n",
            "I wanted to apologize for missing your birthday party. Something came up at work.\n",
            "What's your favorite thing to do on a lazy Sunday afternoon? I love reading.\n",
            "Could you recommend a good mechanic? My car has been making strange noises.\n",
            "I'm really looking forward to the weekend. This work week has been exhausting!\n"
          ]
        }
      ],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1373,
      "metadata": {
        "id": "7qvmCUaQf2FW"
      },
      "outputs": [],
      "source": [
        "# creating an object of tokenizer class\n",
        "tokenizer = Tokenizer(oov_token='<NOTHING>') # if any word came out side the train data it will simple print nothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1374,
      "metadata": {
        "id": "qyeooTX6f6sG"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1375,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TcQK_aBf_z-",
        "outputId": "b3b53358-45f8-4a6c-feaf-05a2cca0443f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<NOTHING>': 1,\n",
              " 'you': 2,\n",
              " 'the': 3,\n",
              " 'i': 4,\n",
              " 'your': 5,\n",
              " 'to': 6,\n",
              " \"i'm\": 7,\n",
              " 'this': 8,\n",
              " 'how': 9,\n",
              " 'have': 10,\n",
              " 'a': 11,\n",
              " 'new': 12,\n",
              " 'it': 13,\n",
              " 'for': 14,\n",
              " 'that': 15,\n",
              " 'really': 16,\n",
              " 'did': 17,\n",
              " 'was': 18,\n",
              " 'just': 19,\n",
              " 'been': 20,\n",
              " 'up': 21,\n",
              " 'weekend': 22,\n",
              " 'today': 23,\n",
              " 'morning': 24,\n",
              " 'last': 25,\n",
              " 'about': 26,\n",
              " 'what': 27,\n",
              " 'so': 28,\n",
              " \"what's\": 29,\n",
              " 'could': 30,\n",
              " 'is': 31,\n",
              " 'do': 32,\n",
              " 'week': 33,\n",
              " 'has': 34,\n",
              " 'on': 35,\n",
              " 'work': 36,\n",
              " 'good': 37,\n",
              " 'thinking': 38,\n",
              " 'day': 39,\n",
              " 'doing': 40,\n",
              " 'had': 41,\n",
              " 'weather': 42,\n",
              " 'we': 43,\n",
              " 'time': 44,\n",
              " 'believe': 45,\n",
              " 'wanted': 46,\n",
              " 'me': 47,\n",
              " 'amazing': 48,\n",
              " 'late': 49,\n",
              " 'like': 50,\n",
              " 'something': 51,\n",
              " 'street': 52,\n",
              " 'nice': 53,\n",
              " 'would': 54,\n",
              " 'restaurant': 55,\n",
              " \"how's\": 56,\n",
              " 'at': 57,\n",
              " 'should': 58,\n",
              " 'are': 59,\n",
              " 'year': 60,\n",
              " 'love': 61,\n",
              " 'out': 62,\n",
              " 'my': 63,\n",
              " 'look': 64,\n",
              " 'reading': 65,\n",
              " 'sleep': 66,\n",
              " 'night': 67,\n",
              " 'any': 68,\n",
              " 'interesting': 69,\n",
              " 'dreams': 70,\n",
              " 'hey': 71,\n",
              " 'there': 72,\n",
              " 'other': 73,\n",
              " 'beautiful': 74,\n",
              " 'outside': 75,\n",
              " 'chance': 76,\n",
              " 'enjoy': 77,\n",
              " 'yet': 78,\n",
              " 'glad': 79,\n",
              " 'finally': 80,\n",
              " 'some': 81,\n",
              " 'catch': 82,\n",
              " 'in': 83,\n",
              " 'life': 84,\n",
              " 'crowded': 85,\n",
              " 'supermarket': 86,\n",
              " 'insane': 87,\n",
              " 'say': 88,\n",
              " 'thank': 89,\n",
              " 'again': 90,\n",
              " 'helping': 91,\n",
              " 'move': 92,\n",
              " \"you're\": 93,\n",
              " 'end': 94,\n",
              " 'going': 95,\n",
              " 'concert': 96,\n",
              " 'mentioned': 97,\n",
              " 'sorry': 98,\n",
              " 'running': 99,\n",
              " 'traffic': 100,\n",
              " 'absolutely': 101,\n",
              " 'terrible': 102,\n",
              " 'feel': 103,\n",
              " 'having': 104,\n",
              " 'lunch': 105,\n",
              " 'craving': 106,\n",
              " 'spicy': 107,\n",
              " 'myself': 108,\n",
              " 'seen': 109,\n",
              " 'coffee': 110,\n",
              " 'shop': 111,\n",
              " 'opened': 112,\n",
              " 'down': 113,\n",
              " 'looks': 114,\n",
              " \"can't\": 115,\n",
              " 'fast': 116,\n",
              " 'gone': 117,\n",
              " 'by': 118,\n",
              " 'friday': 119,\n",
              " 'already': 120,\n",
              " 'grab': 121,\n",
              " 'dinner': 122,\n",
              " 'sometime': 123,\n",
              " 'know': 124,\n",
              " 'great': 125,\n",
              " 'family': 126,\n",
              " 'heard': 127,\n",
              " 'sister': 128,\n",
              " 'baby': 129,\n",
              " 'congratulations': 130,\n",
              " 'tired': 131,\n",
              " 'stayed': 132,\n",
              " 'way': 133,\n",
              " 'too': 134,\n",
              " 'watching': 135,\n",
              " 'show': 136,\n",
              " 'netflix': 137,\n",
              " 'hear': 138,\n",
              " 'big': 139,\n",
              " 'sale': 140,\n",
              " 'happening': 141,\n",
              " 'mall': 142,\n",
              " 'go': 143,\n",
              " 'plan': 144,\n",
              " 'holidays': 145,\n",
              " 'traveling': 146,\n",
              " 'anywhere': 147,\n",
              " 'exciting': 148,\n",
              " 'outfit': 149,\n",
              " 'color': 150,\n",
              " 'brings': 151,\n",
              " 'eyes': 152,\n",
              " 'beautifully': 153,\n",
              " 'help': 154,\n",
              " 'with': 155,\n",
              " 'computer': 156,\n",
              " 'problem': 157,\n",
              " 'completely': 158,\n",
              " 'stuck': 159,\n",
              " 'right': 160,\n",
              " 'now': 161,\n",
              " 'treating': 162,\n",
              " 'lately': 163,\n",
              " 'seem': 164,\n",
              " 'busy': 165,\n",
              " 'these': 166,\n",
              " 'past': 167,\n",
              " 'few': 168,\n",
              " 'weeks': 169,\n",
              " 'redecorating': 170,\n",
              " 'living': 171,\n",
              " 'room': 172,\n",
              " 'think': 173,\n",
              " 'forecast': 174,\n",
              " 'says': 175,\n",
              " 'might': 176,\n",
              " 'rain': 177,\n",
              " 'tomorrow': 178,\n",
              " \"don't\": 179,\n",
              " 'forget': 180,\n",
              " 'umbrella': 181,\n",
              " 'finished': 182,\n",
              " 'most': 183,\n",
              " 'book': 184,\n",
              " 'definitely': 185,\n",
              " 'check': 186,\n",
              " 'tried': 187,\n",
              " 'italian': 188,\n",
              " 'main': 189,\n",
              " 'pasta': 190,\n",
              " 'incredible': 191,\n",
              " 'excited': 192,\n",
              " 'summer': 193,\n",
              " 'vacation': 194,\n",
              " \"we're\": 195,\n",
              " 'planning': 196,\n",
              " 'visit': 197,\n",
              " 'europe': 198,\n",
              " 'feeling': 199,\n",
              " 'much': 200,\n",
              " 'better': 201,\n",
              " 'than': 202,\n",
              " 'saw': 203,\n",
              " 'apologize': 204,\n",
              " 'missing': 205,\n",
              " 'birthday': 206,\n",
              " 'party': 207,\n",
              " 'came': 208,\n",
              " 'favorite': 209,\n",
              " 'thing': 210,\n",
              " 'lazy': 211,\n",
              " 'sunday': 212,\n",
              " 'afternoon': 213,\n",
              " 'recommend': 214,\n",
              " 'mechanic': 215,\n",
              " 'car': 216,\n",
              " 'making': 217,\n",
              " 'strange': 218,\n",
              " 'noises': 219,\n",
              " 'looking': 220,\n",
              " 'forward': 221,\n",
              " 'exhausting': 222}"
            ]
          },
          "execution_count": 1375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the word indes\n",
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1376,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfLz4PogCOO",
        "outputId": "6ccd6767-a490-42ff-a0f7-3056bb3f69af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['<NOTHING>', 'you', 'the', 'i', 'your', 'to', \"i'm\", 'this', 'how', 'have', 'a', 'new', 'it', 'for', 'that', 'really', 'did', 'was', 'just', 'been', 'up', 'weekend', 'today', 'morning', 'last', 'about', 'what', 'so', \"what's\", 'could', 'is', 'do', 'week', 'has', 'on', 'work', 'good', 'thinking', 'day', 'doing', 'had', 'weather', 'we', 'time', 'believe', 'wanted', 'me', 'amazing', 'late', 'like', 'something', 'street', 'nice', 'would', 'restaurant', \"how's\", 'at', 'should', 'are', 'year', 'love', 'out', 'my', 'look', 'reading', 'sleep', 'night', 'any', 'interesting', 'dreams', 'hey', 'there', 'other', 'beautiful', 'outside', 'chance', 'enjoy', 'yet', 'glad', 'finally', 'some', 'catch', 'in', 'life', 'crowded', 'supermarket', 'insane', 'say', 'thank', 'again', 'helping', 'move', \"you're\", 'end', 'going', 'concert', 'mentioned', 'sorry', 'running', 'traffic', 'absolutely', 'terrible', 'feel', 'having', 'lunch', 'craving', 'spicy', 'myself', 'seen', 'coffee', 'shop', 'opened', 'down', 'looks', \"can't\", 'fast', 'gone', 'by', 'friday', 'already', 'grab', 'dinner', 'sometime', 'know', 'great', 'family', 'heard', 'sister', 'baby', 'congratulations', 'tired', 'stayed', 'way', 'too', 'watching', 'show', 'netflix', 'hear', 'big', 'sale', 'happening', 'mall', 'go', 'plan', 'holidays', 'traveling', 'anywhere', 'exciting', 'outfit', 'color', 'brings', 'eyes', 'beautifully', 'help', 'with', 'computer', 'problem', 'completely', 'stuck', 'right', 'now', 'treating', 'lately', 'seem', 'busy', 'these', 'past', 'few', 'weeks', 'redecorating', 'living', 'room', 'think', 'forecast', 'says', 'might', 'rain', 'tomorrow', \"don't\", 'forget', 'umbrella', 'finished', 'most', 'book', 'definitely', 'check', 'tried', 'italian', 'main', 'pasta', 'incredible', 'excited', 'summer', 'vacation', \"we're\", 'planning', 'visit', 'europe', 'feeling', 'much', 'better', 'than', 'saw', 'apologize', 'missing', 'birthday', 'party', 'came', 'favorite', 'thing', 'lazy', 'sunday', 'afternoon', 'recommend', 'mechanic', 'car', 'making', 'strange', 'noises', 'looking', 'forward', 'exhausting'])"
            ]
          },
          "execution_count": 1376,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the words\n",
        "tokenizer.word_index.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1377,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amN1KgkvggiH",
        "outputId": "e52e9eff-f710-4e08-f894-d91c5a6d23cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222])"
            ]
          },
          "execution_count": 1377,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the values\n",
        "tokenizer.word_index.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1378,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg3qV7JlkKPH",
        "outputId": "eaf14c65-f9c9-4fb5-e11d-d6be59659bbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "execution_count": 1378,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.word_index.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1379,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svfldnylgi1O",
        "outputId": "4175440a-f919-4a1c-a9a0-e4ab5bbb3490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70]\n",
            "[71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40]\n",
            "[27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78]\n",
            "[7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84]\n",
            "[30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87]\n",
            "[4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48]\n",
            "[9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97]\n",
            "[7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24]\n",
            "[27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108]\n",
            "[10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53]\n",
            "[4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120]\n",
            "[54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55]\n",
            "[56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130]\n",
            "[7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137]\n",
            "[17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143]\n",
            "[29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60]\n",
            "[4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153]\n",
            "[30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161]\n",
            "[56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169]\n",
            "[7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53]\n",
            "[3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181]\n",
            "[4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62]\n",
            "[10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191]\n",
            "[7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60]\n",
            "[9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2]\n",
            "[4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36]\n",
            "[29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65]\n",
            "[30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219]\n",
            "[7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]\n"
          ]
        }
      ],
      "source": [
        "# convert the sentences based on the text sequence\n",
        "for sentence in data.split(\"\\n\"):\n",
        "  if sentence.strip():\n",
        "    print(tokenizer.texts_to_sequences([sentence])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1380,
      "metadata": {
        "id": "GvTkEIJWhFbf"
      },
      "outputs": [],
      "source": [
        "# making the input and the output sequence\n",
        "input_sequences = []\n",
        "for sentence in data.split('\\n'):\n",
        "  if sentence.strip():\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0] # convert the sentences based on the text sequence\n",
        "\n",
        "    for i in range(1,len(tokenized_sentence)):\n",
        "      input_sequences.append(tokenized_sentence[:i+1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4B1mrA_-iU7I",
        "outputId": "1088d66c-f218-4df8-be3e-24a9a0064856"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nso if X = 36 then y = 23\\nif X = 36,23 then y = 8\\n'"
            ]
          },
          "execution_count": 1381,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for 36 the next word will be 23\n",
        "# for 23 and 36 the next word will be 8\n",
        "\n",
        "\"\"\"\n",
        "so if X = 36 then y = 23\n",
        "if X = 36,23 then y = 8\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOi9rLLSiR4X",
        "outputId": "fb94e526-14ca-4d40-93ed-c57d873eaac5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[37, 24],\n",
              " [37, 24, 9],\n",
              " [37, 24, 9, 17],\n",
              " [37, 24, 9, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66],\n",
              " [37, 24, 9, 17, 2, 66, 25],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69],\n",
              " [37, 24, 9, 17, 2, 66, 25, 67, 17, 2, 10, 68, 69, 70],\n",
              " [71, 72],\n",
              " [71, 72, 4],\n",
              " [71, 72, 4, 18],\n",
              " [71, 72, 4, 18, 19],\n",
              " [71, 72, 4, 18, 19, 38],\n",
              " [71, 72, 4, 18, 19, 38, 26],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20],\n",
              " [71, 72, 4, 18, 19, 38, 26, 2, 3, 73, 39, 9, 10, 2, 20, 40],\n",
              " [27, 11],\n",
              " [27, 11, 74],\n",
              " [27, 11, 74, 39],\n",
              " [27, 11, 74, 39, 75],\n",
              " [27, 11, 74, 39, 75, 10],\n",
              " [27, 11, 74, 39, 75, 10, 2],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42],\n",
              " [27, 11, 74, 39, 75, 10, 2, 41, 11, 76, 6, 77, 3, 42, 78],\n",
              " [7, 28],\n",
              " [7, 28, 79],\n",
              " [7, 28, 79, 43],\n",
              " [7, 28, 79, 43, 80],\n",
              " [7, 28, 79, 43, 80, 10],\n",
              " [7, 28, 79, 43, 80, 10, 81],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5],\n",
              " [7, 28, 79, 43, 80, 10, 81, 44, 6, 82, 21, 29, 12, 83, 5, 84],\n",
              " [30, 2],\n",
              " [30, 2, 45],\n",
              " [30, 2, 45, 9],\n",
              " [30, 2, 45, 9, 85],\n",
              " [30, 2, 45, 9, 85, 3],\n",
              " [30, 2, 45, 9, 85, 3, 86],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18],\n",
              " [30, 2, 45, 9, 85, 3, 86, 18, 8, 24, 13, 18, 87],\n",
              " [4, 19],\n",
              " [4, 19, 46],\n",
              " [4, 19, 46, 6],\n",
              " [4, 19, 46, 6, 88],\n",
              " [4, 19, 46, 6, 88, 89],\n",
              " [4, 19, 46, 6, 88, 89, 2],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93],\n",
              " [4, 19, 46, 6, 88, 89, 2, 90, 14, 91, 47, 92, 25, 22, 93, 48],\n",
              " [9, 18],\n",
              " [9, 18, 5],\n",
              " [9, 18, 5, 22],\n",
              " [9, 18, 5, 22, 17],\n",
              " [9, 18, 5, 22, 17, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2],\n",
              " [9, 18, 5, 22, 17, 2, 94, 21, 95, 6, 15, 96, 2, 97],\n",
              " [7, 16],\n",
              " [7, 16, 98],\n",
              " [7, 16, 98, 7],\n",
              " [7, 16, 98, 7, 99],\n",
              " [7, 16, 98, 7, 99, 49],\n",
              " [7, 16, 98, 7, 99, 49, 100],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8],\n",
              " [7, 16, 98, 7, 99, 49, 100, 31, 101, 102, 8, 24],\n",
              " [27, 32],\n",
              " [27, 32, 2],\n",
              " [27, 32, 2, 103],\n",
              " [27, 32, 2, 103, 50],\n",
              " [27, 32, 2, 103, 50, 104],\n",
              " [27, 32, 2, 103, 50, 104, 14],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107],\n",
              " [27, 32, 2, 103, 50, 104, 14, 105, 23, 7, 106, 51, 107, 108],\n",
              " [10, 2],\n",
              " [10, 2, 109],\n",
              " [10, 2, 109, 3],\n",
              " [10, 2, 109, 3, 12],\n",
              " [10, 2, 109, 3, 12, 110],\n",
              " [10, 2, 109, 3, 12, 110, 111],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16],\n",
              " [10, 2, 109, 3, 12, 110, 111, 15, 112, 113, 3, 52, 13, 114, 16, 53],\n",
              " [4, 115],\n",
              " [4, 115, 45],\n",
              " [4, 115, 45, 9],\n",
              " [4, 115, 45, 9, 116],\n",
              " [4, 115, 45, 9, 116, 8],\n",
              " [4, 115, 45, 9, 116, 8, 33],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119],\n",
              " [4, 115, 45, 9, 116, 8, 33, 34, 117, 118, 31, 13, 119, 120],\n",
              " [54, 2],\n",
              " [54, 2, 50],\n",
              " [54, 2, 50, 6],\n",
              " [54, 2, 50, 6, 121],\n",
              " [54, 2, 50, 6, 121, 122],\n",
              " [54, 2, 50, 6, 121, 122, 123],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12],\n",
              " [54, 2, 50, 6, 121, 122, 123, 8, 33, 4, 124, 11, 125, 12, 55],\n",
              " [56, 5],\n",
              " [56, 5, 126],\n",
              " [56, 5, 126, 40],\n",
              " [56, 5, 126, 40, 4],\n",
              " [56, 5, 126, 40, 4, 127],\n",
              " [56, 5, 126, 40, 4, 127, 5],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129],\n",
              " [56, 5, 126, 40, 4, 127, 5, 128, 19, 41, 11, 129, 130],\n",
              " [7, 28],\n",
              " [7, 28, 131],\n",
              " [7, 28, 131, 23],\n",
              " [7, 28, 131, 23, 4],\n",
              " [7, 28, 131, 23, 4, 132],\n",
              " [7, 28, 131, 23, 4, 132, 21],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35],\n",
              " [7, 28, 131, 23, 4, 132, 21, 133, 134, 49, 135, 15, 12, 136, 35, 137],\n",
              " [17, 2],\n",
              " [17, 2, 138],\n",
              " [17, 2, 138, 26],\n",
              " [17, 2, 138, 26, 3],\n",
              " [17, 2, 138, 26, 3, 139],\n",
              " [17, 2, 138, 26, 3, 139, 140],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58],\n",
              " [17, 2, 138, 26, 3, 139, 140, 141, 57, 3, 142, 8, 22, 43, 58, 143],\n",
              " [29, 5],\n",
              " [29, 5, 144],\n",
              " [29, 5, 144, 14],\n",
              " [29, 5, 144, 14, 3],\n",
              " [29, 5, 144, 14, 3, 145],\n",
              " [29, 5, 144, 14, 3, 145, 59],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8],\n",
              " [29, 5, 144, 14, 3, 145, 59, 2, 146, 147, 148, 8, 60],\n",
              " [4, 61],\n",
              " [4, 61, 5],\n",
              " [4, 61, 5, 149],\n",
              " [4, 61, 5, 149, 23],\n",
              " [4, 61, 5, 149, 23, 15],\n",
              " [4, 61, 5, 149, 23, 15, 150],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152],\n",
              " [4, 61, 5, 149, 23, 15, 150, 16, 151, 62, 5, 152, 153],\n",
              " [30, 2],\n",
              " [30, 2, 154],\n",
              " [30, 2, 154, 47],\n",
              " [30, 2, 154, 47, 155],\n",
              " [30, 2, 154, 47, 155, 8],\n",
              " [30, 2, 154, 47, 155, 8, 156],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160],\n",
              " [30, 2, 154, 47, 155, 8, 156, 157, 7, 158, 159, 160, 161],\n",
              " [56, 36],\n",
              " [56, 36, 20],\n",
              " [56, 36, 20, 162],\n",
              " [56, 36, 20, 162, 2],\n",
              " [56, 36, 20, 162, 2, 163],\n",
              " [56, 36, 20, 162, 2, 163, 2],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168],\n",
              " [56, 36, 20, 162, 2, 163, 2, 164, 16, 165, 166, 167, 168, 169],\n",
              " [7, 38],\n",
              " [7, 38, 26],\n",
              " [7, 38, 26, 170],\n",
              " [7, 38, 26, 170, 63],\n",
              " [7, 38, 26, 170, 63, 171],\n",
              " [7, 38, 26, 170, 63, 171, 172],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64],\n",
              " [7, 38, 26, 170, 63, 171, 172, 27, 32, 2, 173, 54, 64, 53],\n",
              " [3, 42],\n",
              " [3, 42, 174],\n",
              " [3, 42, 174, 175],\n",
              " [3, 42, 174, 175, 13],\n",
              " [3, 42, 174, 175, 13, 176],\n",
              " [3, 42, 174, 175, 13, 176, 177],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5],\n",
              " [3, 42, 174, 175, 13, 176, 177, 178, 179, 180, 5, 181],\n",
              " [4, 19],\n",
              " [4, 19, 182],\n",
              " [4, 19, 182, 65],\n",
              " [4, 19, 182, 65, 3],\n",
              " [4, 19, 182, 65, 3, 183],\n",
              " [4, 19, 182, 65, 3, 183, 48],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13],\n",
              " [4, 19, 182, 65, 3, 183, 48, 184, 2, 58, 185, 186, 13, 62],\n",
              " [10, 2],\n",
              " [10, 2, 187],\n",
              " [10, 2, 187, 15],\n",
              " [10, 2, 187, 15, 12],\n",
              " [10, 2, 187, 15, 12, 188],\n",
              " [10, 2, 187, 15, 12, 188, 55],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31],\n",
              " [10, 2, 187, 15, 12, 188, 55, 35, 189, 52, 3, 190, 31, 191],\n",
              " [7, 28],\n",
              " [7, 28, 192],\n",
              " [7, 28, 192, 14],\n",
              " [7, 28, 192, 14, 193],\n",
              " [7, 28, 192, 14, 193, 194],\n",
              " [7, 28, 192, 14, 193, 194, 195],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8],\n",
              " [7, 28, 192, 14, 193, 194, 195, 196, 6, 197, 198, 8, 60],\n",
              " [9, 59],\n",
              " [9, 59, 2],\n",
              " [9, 59, 2, 199],\n",
              " [9, 59, 2, 199, 23],\n",
              " [9, 59, 2, 199, 23, 2],\n",
              " [9, 59, 2, 199, 23, 2, 64],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203],\n",
              " [9, 59, 2, 199, 23, 2, 64, 200, 201, 202, 3, 25, 44, 4, 203, 2],\n",
              " [4, 46],\n",
              " [4, 46, 6],\n",
              " [4, 46, 6, 204],\n",
              " [4, 46, 6, 204, 14],\n",
              " [4, 46, 6, 204, 14, 205],\n",
              " [4, 46, 6, 204, 14, 205, 5],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57],\n",
              " [4, 46, 6, 204, 14, 205, 5, 206, 207, 51, 208, 21, 57, 36],\n",
              " [29, 5],\n",
              " [29, 5, 209],\n",
              " [29, 5, 209, 210],\n",
              " [29, 5, 209, 210, 6],\n",
              " [29, 5, 209, 210, 6, 32],\n",
              " [29, 5, 209, 210, 6, 32, 35],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61],\n",
              " [29, 5, 209, 210, 6, 32, 35, 11, 211, 212, 213, 4, 61, 65],\n",
              " [30, 2],\n",
              " [30, 2, 214],\n",
              " [30, 2, 214, 11],\n",
              " [30, 2, 214, 11, 37],\n",
              " [30, 2, 214, 11, 37, 215],\n",
              " [30, 2, 214, 11, 37, 215, 63],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218],\n",
              " [30, 2, 214, 11, 37, 215, 63, 216, 34, 20, 217, 218, 219],\n",
              " [7, 16],\n",
              " [7, 16, 220],\n",
              " [7, 16, 220, 221],\n",
              " [7, 16, 220, 221, 6],\n",
              " [7, 16, 220, 221, 6, 3],\n",
              " [7, 16, 220, 221, 6, 3, 22],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20],\n",
              " [7, 16, 220, 221, 6, 3, 22, 8, 36, 33, 34, 20, 222]]"
            ]
          },
          "execution_count": 1382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1383,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIjtdOcOiw5f",
        "outputId": "c2abbcb1-9e33-4677-d06c-e43e35904288"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 1383,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding the maximum length\n",
        "maximum_len = max([len(x) for x in input_sequences])\n",
        "maximum_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1384,
      "metadata": {
        "id": "xbAoCv00iw2X"
      },
      "outputs": [],
      "source": [
        "# padding (pre padding)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = maximum_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1385,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQFbSHEciw0G",
        "outputId": "c23cfdfa-613b-46bd-8f55-87b9ac6f2773"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  37,  24],\n",
              "       [  0,   0,   0, ...,  37,  24,   9],\n",
              "       [  0,   0,   0, ...,  24,   9,  17],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  36,  33,  34],\n",
              "       [  0,   0,   0, ...,  33,  34,  20],\n",
              "       [  0,   0,   0, ...,  34,  20, 222]], dtype=int32)"
            ]
          },
          "execution_count": 1385,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1386,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2CWNeoJiwwX",
        "outputId": "35174ebd-8247-4f95-9fd1-7f22fdbcc7a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 16)"
            ]
          },
          "execution_count": 1386,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_input_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1387,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TtGo25xiwsI",
        "outputId": "ac7a7985-82b3-4ccf-dd86-f3a5f14b2269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0, 37],\n",
              "       [ 0,  0,  0, ...,  0, 37, 24],\n",
              "       [ 0,  0,  0, ..., 37, 24,  9],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  8, 36, 33],\n",
              "       [ 0,  0,  0, ..., 36, 33, 34],\n",
              "       [ 0,  0,  0, ..., 33, 34, 20]], dtype=int32)"
            ]
          },
          "execution_count": 1387,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1388,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6DaSq8j0L2",
        "outputId": "878d8d45-18de-40fe-bd2c-fc6956fc1fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 15)"
            ]
          },
          "execution_count": 1388,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1389,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxZQv2UGiwpb",
        "outputId": "70f6a09e-bc46-47a3-bc85-6686b7078cb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 24,   9,  17,   2,  66,  25,  67,  17,   2,  10,  68,  69,  70,\n",
              "        72,   4,  18,  19,  38,  26,   2,   3,  73,  39,   9,  10,   2,\n",
              "        20,  40,  11,  74,  39,  75,  10,   2,  41,  11,  76,   6,  77,\n",
              "         3,  42,  78,  28,  79,  43,  80,  10,  81,  44,   6,  82,  21,\n",
              "        29,  12,  83,   5,  84,   2,  45,   9,  85,   3,  86,  18,   8,\n",
              "        24,  13,  18,  87,  19,  46,   6,  88,  89,   2,  90,  14,  91,\n",
              "        47,  92,  25,  22,  93,  48,  18,   5,  22,  17,   2,  94,  21,\n",
              "        95,   6,  15,  96,   2,  97,  16,  98,   7,  99,  49, 100,  31,\n",
              "       101, 102,   8,  24,  32,   2, 103,  50, 104,  14, 105,  23,   7,\n",
              "       106,  51, 107, 108,   2, 109,   3,  12, 110, 111,  15, 112, 113,\n",
              "         3,  52,  13, 114,  16,  53, 115,  45,   9, 116,   8,  33,  34,\n",
              "       117, 118,  31,  13, 119, 120,   2,  50,   6, 121, 122, 123,   8,\n",
              "        33,   4, 124,  11, 125,  12,  55,   5, 126,  40,   4, 127,   5,\n",
              "       128,  19,  41,  11, 129, 130,  28, 131,  23,   4, 132,  21, 133,\n",
              "       134,  49, 135,  15,  12, 136,  35, 137,   2, 138,  26,   3, 139,\n",
              "       140, 141,  57,   3, 142,   8,  22,  43,  58, 143,   5, 144,  14,\n",
              "         3, 145,  59,   2, 146, 147, 148,   8,  60,  61,   5, 149,  23,\n",
              "        15, 150,  16, 151,  62,   5, 152, 153,   2, 154,  47, 155,   8,\n",
              "       156, 157,   7, 158, 159, 160, 161,  36,  20, 162,   2, 163,   2,\n",
              "       164,  16, 165, 166, 167, 168, 169,  38,  26, 170,  63, 171, 172,\n",
              "        27,  32,   2, 173,  54,  64,  53,  42, 174, 175,  13, 176, 177,\n",
              "       178, 179, 180,   5, 181,  19, 182,  65,   3, 183,  48, 184,   2,\n",
              "        58, 185, 186,  13,  62,   2, 187,  15,  12, 188,  55,  35, 189,\n",
              "        52,   3, 190,  31, 191,  28, 192,  14, 193, 194, 195, 196,   6,\n",
              "       197, 198,   8,  60,  59,   2, 199,  23,   2,  64, 200, 201, 202,\n",
              "         3,  25,  44,   4, 203,   2,  46,   6, 204,  14, 205,   5, 206,\n",
              "       207,  51, 208,  21,  57,  36,   5, 209, 210,   6,  32,  35,  11,\n",
              "       211, 212, 213,   4,  61,  65,   2, 214,  11,  37, 215,  63, 216,\n",
              "        34,  20, 217, 218, 219,  16, 220, 221,   6,   3,  22,   8,  36,\n",
              "        33,  34,  20, 222], dtype=int32)"
            ]
          },
          "execution_count": 1389,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = padded_input_sequences[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1390,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehDrOC6vjyRI",
        "outputId": "9fd62ec3-9cda-48f8-ae69-ffe9b64b0824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381,)"
            ]
          },
          "execution_count": 1390,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1391,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2jsydhpZzI",
        "outputId": "9651368a-1ae8-484c-f99d-d3e6fd1ad9ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "execution_count": 1391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) +1 # +1 fo including the zero index\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1392,
      "metadata": {
        "id": "rWhaAC4Xj8cw"
      },
      "outputs": [],
      "source": [
        "# applying One-Hot-Encoding on the traget column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1393,
      "metadata": {
        "id": "wnbc0HJQiwnG"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y,num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1394,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYe6jmOviwkR",
        "outputId": "2a871861-eea4-472e-bdd8-96b04a402596"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(381, 223)"
            ]
          },
          "execution_count": 1394,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1395,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmgP50d0muMo",
        "outputId": "47654f73-5970-493f-df68-d6a2cb1a717a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "223\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.word_index) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1396,
      "metadata": {
        "id": "3R4qAkAwiwcm"
      },
      "outputs": [],
      "source": [
        "# makin the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1397,
      "metadata": {
        "id": "JLBlGm6siwXv"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1398,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjLm37GEymwg",
        "outputId": "e30ac90c-9b61-4c8d-c32d-f2fad45a97e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the vocab size or the total word size is 223\n",
            "the maximun length sentence in the data is 16\n"
          ]
        }
      ],
      "source": [
        "print(f\"the vocab size or the total word size is {vocab_size}\")\n",
        "print(f\"the maximun length sentence in the data is {maximum_len}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nFOR Embedding layer:\\n    input_dim:\\n    - Meaning: This is the size of the vocabulary, i.e., the number of unique words or tokens in your dataset\\n\\n    output_dim:\\n    - Meaning: This specifies the dimensionality of the output embedding vectors for each word.\\n\\n    input_length:\\n    - Meaning: This specifies the length of the input sequences to the Embedding layer (i.e., the max number of words per sequence).\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "FOR Embedding layer:\n",
        "    input_dim:\n",
        "    - Meaning: This is the size of the vocabulary, i.e., the number of unique words or tokens in your dataset\n",
        "\n",
        "    output_dim:\n",
        "    - Meaning: This specifies the dimensionality of the output embedding vectors for each word.\n",
        "\n",
        "    input_length:\n",
        "    - Meaning: This specifies the length of the input sequences to the Embedding layer (i.e., the max number of words per sequence).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1399,
      "metadata": {
        "id": "XLjR2vajiwVD"
      },
      "outputs": [],
      "source": [
        "model.add(Embedding(input_dim=vocab_size,output_dim=50,input_shape=(maximum_len-1,)))\n",
        "model.add(Bidirectional(SimpleRNN(40,activation='relu'))) # Bidirectional RNN\n",
        "model.add(Dense(vocab_size,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1400,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "X0zG2BBAliMQ",
        "outputId": "e5bfe261-2069-48dd-9f4d-8ebd74d8b081"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_39\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_39\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,150</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,280</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">223</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,063</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_41 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m11,150\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m7,280\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m223\u001b[0m)            │        \u001b[38;5;34m18,063\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,493</span> (142.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,493\u001b[0m (142.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,493</span> (142.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,493\u001b[0m (142.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1401,
      "metadata": {
        "id": "az_uQXZ7lmg_"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1402,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcoJt-k_luZI",
        "outputId": "469bf362-b340-417b-e92f-84f6fed8bb35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.0050 - loss: 5.4059\n",
            "Epoch 2/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0514 - loss: 5.3862\n",
            "Epoch 3/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0749 - loss: 5.3589\n",
            "Epoch 4/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0776 - loss: 5.2717\n",
            "Epoch 5/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0528 - loss: 5.1103\n",
            "Epoch 6/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0574 - loss: 4.9872\n",
            "Epoch 7/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0644 - loss: 4.9758\n",
            "Epoch 8/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0542 - loss: 4.8525\n",
            "Epoch 9/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0721 - loss: 4.8246\n",
            "Epoch 10/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0505 - loss: 4.7898\n",
            "Epoch 11/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0720 - loss: 4.7139\n",
            "Epoch 12/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0657 - loss: 4.5401\n",
            "Epoch 13/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0801 - loss: 4.4844\n",
            "Epoch 14/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0817 - loss: 4.3897\n",
            "Epoch 15/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1105 - loss: 4.1329\n",
            "Epoch 16/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1364 - loss: 3.9342\n",
            "Epoch 17/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2096 - loss: 3.7396\n",
            "Epoch 18/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2053 - loss: 3.5793\n",
            "Epoch 19/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2675 - loss: 3.2129\n",
            "Epoch 20/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3663 - loss: 2.8041\n",
            "Epoch 21/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4752 - loss: 2.3780\n",
            "Epoch 22/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6178 - loss: 1.8489\n",
            "Epoch 23/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7373 - loss: 1.5408\n",
            "Epoch 24/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7157 - loss: 1.2632\n",
            "Epoch 25/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7541 - loss: 1.1092\n",
            "Epoch 26/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7500 - loss: 1.0570\n",
            "Epoch 27/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8346 - loss: 0.8075\n",
            "Epoch 28/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8164 - loss: 0.8010\n",
            "Epoch 29/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8647 - loss: 0.6692\n",
            "Epoch 30/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8807 - loss: 0.5916\n",
            "Epoch 31/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8496 - loss: 0.6602\n",
            "Epoch 32/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8639 - loss: 0.5447\n",
            "Epoch 33/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9019 - loss: 0.4817\n",
            "Epoch 34/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.4944\n",
            "Epoch 35/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.4350\n",
            "Epoch 36/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8905 - loss: 0.4306\n",
            "Epoch 37/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9080 - loss: 0.3787\n",
            "Epoch 38/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9119 - loss: 0.3498\n",
            "Epoch 39/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9357 - loss: 0.3244\n",
            "Epoch 40/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9219 - loss: 0.3160\n",
            "Epoch 41/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9157 - loss: 0.3283\n",
            "Epoch 42/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9059 - loss: 0.3386\n",
            "Epoch 43/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9088 - loss: 0.3584\n",
            "Epoch 44/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9023 - loss: 0.3721\n",
            "Epoch 45/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8950 - loss: 0.3639\n",
            "Epoch 46/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8803 - loss: 0.3761\n",
            "Epoch 47/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9194 - loss: 0.3449\n",
            "Epoch 48/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9242 - loss: 0.3465\n",
            "Epoch 49/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9072 - loss: 0.3030\n",
            "Epoch 50/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.3083\n",
            "Epoch 51/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9033 - loss: 0.3000\n",
            "Epoch 52/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9396 - loss: 0.2081\n",
            "Epoch 53/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9261 - loss: 0.2445\n",
            "Epoch 54/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9424 - loss: 0.2241\n",
            "Epoch 55/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.1986\n",
            "Epoch 56/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.1707\n",
            "Epoch 57/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9458 - loss: 0.2043\n",
            "Epoch 58/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9453 - loss: 0.2152\n",
            "Epoch 59/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9420 - loss: 0.1869\n",
            "Epoch 60/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9529 - loss: 0.1582\n",
            "Epoch 61/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9554 - loss: 0.1457\n",
            "Epoch 62/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9584 - loss: 0.1401\n",
            "Epoch 63/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9426 - loss: 0.1994\n",
            "Epoch 64/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1774\n",
            "Epoch 65/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9415 - loss: 0.1832\n",
            "Epoch 66/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9500 - loss: 0.1572\n",
            "Epoch 67/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9420 - loss: 0.1697\n",
            "Epoch 68/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.1757\n",
            "Epoch 69/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9360 - loss: 0.1631\n",
            "Epoch 70/70\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.1126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f488e66ed0>"
            ]
          },
          "execution_count": 1402,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X,y,epochs=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1403,
      "metadata": {
        "id": "8l7y8sH7lwux"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def predict_next_word(user_text, num_words=9):\n",
        "    \"\"\"\n",
        "    Predicts the next words iteratively based on the given seed text and generates a sequence of words.\n",
        "\n",
        "    Arguments:\n",
        "    user_text -- the initial text (string) to start the prediction\n",
        "    num_words -- the number of words to predict iteratively (default is 10)\n",
        "\n",
        "    Returns:\n",
        "    A string containing the seed text followed by the predicted words.\n",
        "    \"\"\"\n",
        "    # Loop to predict 'num_words' words one by one\n",
        "    for i in range(num_words):\n",
        "        # Step 1: Tokenize the seed text into a sequence of integers\n",
        "        # This converts each word in the seed text into a corresponding integer based on the tokenizer's word index\n",
        "        token_text = tokenizer.texts_to_sequences([user_text])[0]\n",
        "\n",
        "        # Step 2: Pad the tokenized sequence to ensure it matches the model's expected input shape\n",
        "        # Padding ensures that all input sequences are the same length (max_len), and 'pre' means padding is added at the start\n",
        "        padded_token_text = pad_sequences([token_text], maxlen=maximum_len, padding='pre')\n",
        "\n",
        "        # Step 3: Use the model to predict the next word's probabilities\n",
        "        # The model outputs a probability distribution over the vocabulary for the next word\n",
        "        pred = model.predict(padded_token_text)\n",
        "\n",
        "        # Step 4: Get the index of the word with the highest predicted probability\n",
        "        # 'np.argmax' returns the index of the word with the highest probability\n",
        "        pred_word_index = np.argmax(pred)\n",
        "\n",
        "        # Step 5: Retrieve the predicted word from the tokenizer's word index\n",
        "        # We use the word index to map the predicted index back to the corresponding word\n",
        "        pred_word = tokenizer.index_word.get(pred_word_index, None)\n",
        "\n",
        "        # Step 6: Add the predicted word to the seed text\n",
        "        # If a valid word is predicted, append it to the final pred\n",
        "        if pred_word:\n",
        "            user_text = user_text + \" \" + pred_word\n",
        "            print(user_text)  # Print the updated seed text with the new predicted word\n",
        "\n",
        "        # Step 7: Sleep for 2 seconds before predicting the next word\n",
        "        # This introduces a slight delay between predictions to simulate more natural generation\n",
        "        time.sleep(2)\n",
        "\n",
        "    return user_text  # Return the final generated text containing the original seed text and the predicted words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1404,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWRnd3gdqt8A",
        "outputId": "799c9eba-eba9-474c-8d6a-f2f2a3bcd31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "Good morning how\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Good morning how did you sleep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Good morning how did you sleep last\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Good morning how did you sleep last night\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Good morning how did you sleep last night did\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you sleep last night did you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Good morning how did you sleep last night did you have\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Good morning\"\n",
        "generated_text = predict_next_word(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1404,
      "metadata": {
        "id": "yhaPvG9Mu7Tz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
